[
  {
    "objectID": "machine-learning/delong_test.html",
    "href": "machine-learning/delong_test.html",
    "title": "AUC",
    "section": "",
    "text": "title: Delong test\nAUC là viết tắt của “Area Under the ROC Curve” trong tiếng Anh, dịch sang tiếng Việt là “Diện tích dưới đường cong ROC”. Đây là một phép đo quan trọng trong đánh giá hiệu suất của mô hình phân loại (classifier) trong trường hợp binary classification (phân loại nhị phân).\nĐể hiểu AUC, hãy cùng nhau xem xét đến đường cong ROC (Receiver Operating Characteristic curve). ROC curve biểu diễn sự tương quan giữa tỷ lệ True Positive Rate (TPR) và tỷ lệ False Positive Rate (FPR) của mô hình phân loại, khi ngưỡng phân loại thay đổi từ 0 đến 1.\nAUC là diện tích nằm dưới đường cong ROC và nó thể hiện khả năng của mô hình phân loại phân biệt giữa hai lớp positive và negative. AUC càng lớn thì mô hình càng có khả năng phân loại tốt hơn, với AUC = 1 thể hiện mô hình hoàn hảo, trong khi AUC = 0.5 chỉ ra mô hình không khác biệt so với một dự đoán ngẫu nhiên.\nAUC là một phép đo định lượng và phổ biến trong đánh giá hiệu suất của các mô hình phân loại như Logistic Regression, Support Vector Machines (SVM), Random Forest, Neural Networks, và nhiều mô hình khác.\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\n# Tạo dữ liệu mẫu cho binary classification\nX, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n\n# Chia dữ liệu thành tập train và tập test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Tạo mô hình Logistic Regression và huấn luyện trên tập train\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Tính xác suất dự đoán của mô hình trên tập test\ny_prob = model.predict_proba(X_test)[:, 1]\n\n# Tính đường cong ROC và AUC\nfpr, tpr, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(fpr, tpr)\n\n# Vẽ biểu đồ AUC\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()"
  },
  {
    "objectID": "machine-learning/delong_test.html#liên-hệ-auc-và-thống-kê-mann-whitney",
    "href": "machine-learning/delong_test.html#liên-hệ-auc-và-thống-kê-mann-whitney",
    "title": "AUC",
    "section": "Liên hệ AUC và thống kê Mann-Whitney",
    "text": "Liên hệ AUC và thống kê Mann-Whitney\n\nThống kê Mann-Whitney (U-test):\nGiả sử bạn có hai nhóm dữ liệu độc lập, (X) và (Y), với kích thước lần lượt là (n_x) và (n_y). Để tính U-statistic, bạn cần xếp hạng dữ liệu trong mỗi nhóm và tính tổng các xếp hạng trong nhóm (X), ký hiệu là (R_X). Sau đó, U-statistic được tính bằng công thức:\n\\[ U = n_x \\cdot n_y + \\frac{n_x \\cdot (n_x + 1)}{2} - R_X \\]\nNếu (U) là giá trị U-statistic (thống kê Mann-Whitney), thì AUC được tính như sau:\n\\[ AUC = \\frac{U - \\frac{n_x \\cdot (n_x + 1)}{2}}{n_x \\cdot n_y} \\]\nDeLong’s test:\nGiả sử bạn có hai mô hình phân loại và đã tính được các xác suất dự đoán của chúng trên tập dữ liệu kiểm tra. Để thực hiện kiểm định DeLong, bạn cần tính U-statistic và phương sai của U-statistic (Var(U)) như đã giải thích trước đó.\nTiếp theo, để tính Z-score, bạn cần có AUC của hai mô hình ((AUC_1) và (AUC_2)) và Var(U) như sau:\n\\[ Z = \\frac{AUC_1 - AUC_2}{\\sqrt{\\text{Var}(U)}} \\]\nSau đó, sử dụng Z-score để tính p-value, và nếu p-value nhỏ hơn mức ý nghĩa đã chọn (thường là 0.05), bạn có thể kết luận rằng có sự khác biệt đáng kể giữa AUC của hai mô hình.\nCông thức tính khoảng tin cậy (confidence interval) cho AUC dựa trên phương pháp DeLong như sau:\nGiả sử bạn đã tính được U-statistic (U) và Var(U) từ kiểm định DeLong, thì khoảng tin cậy 95% cho AUC sẽ được tính bằng công thức sau:\n\\[ \\text{CI}_{\\text{lower}} = AUC - z_{\\alpha/2} \\cdot \\sqrt{\\text{Var}(U)} \\]\n\\[ \\text{CI}_{\\text{upper}} = AUC + z_{\\alpha/2} \\cdot \\sqrt{\\text{Var}(U)} \\]\nTrong đó:\n\nAUC là diện tích dưới đường cong ROC đã tính từ mô hình phân loại và tập dữ liệu.\nVar(U) là phương sai của U-statistic, tính từ kiểm định DeLong.\n( z_{/2} ) là giá trị thống kê từ phân phối chuẩn tương ứng với mức đáng tin cậy 95%. Với mức đáng tin cậy 95%, ( = 0.05 ), nên ( z_{/2} ) tương ứng với giá trị thống kê 1.96.\n\nKhoảng tin cậy này sẽ cho phép bạn ước tính khoảng giá trị mà AUC có thể nằm trong với mức đáng tin cậy 95%.\n\\[ \\text{var(U)} = \\frac{U \\cdot (n_{\\text{positives}} + n_{\\text{negatives}} + 1) \\cdot (n_{\\text{positives}} + n_{\\text{negatives}} - U)}{12} \\]\nTrong đó:\n\n( U ) là giá trị U-statistic đã tính trước đó.\n( n_{} ) là số lượng điểm dữ liệu positive (nhãn dương) trong tập dữ liệu.\n( n_{} ) là số lượng điểm dữ liệu negative (nhãn âm) trong tập dữ liệu."
  },
  {
    "objectID": "machine-learning/delong_test.html#tính-khoảng-tin-cậy-auc-sử-dụng-phương-pháp-delong",
    "href": "machine-learning/delong_test.html#tính-khoảng-tin-cậy-auc-sử-dụng-phương-pháp-delong",
    "title": "AUC",
    "section": "Tính khoảng tin cậy AUC sử dụng phương pháp Delong",
    "text": "Tính khoảng tin cậy AUC sử dụng phương pháp Delong\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score\nfrom scipy.stats import norm\n\n# Tính AUC cho mô hình ban đầu\nauc_model = roc_auc_score(y_test, y_prob)\n\n# Tính U-statistic và phương sai của U-statistic\nn_positives = np.sum(y_test)\nn_negatives = len(y_test) - n_positives\nU = n_positives * n_negatives\nvar_U = (U * (n_positives + n_negatives + 1) * (n_positives + n_negatives - U)) / 12\n\n# Tính giá trị Z-score tương ứng với mức đáng tin cậy 95%\nalpha = 0.05\nz_score = norm.ppf(1 - alpha / 2)\n\n# Tính khoảng tin cậy 95% cho AUC bằng phương pháp DeLong\nlower_bound = auc_model - z_score * np.sqrt(var_U)\nupper_bound = auc_model + z_score * np.sqrt(var_U)\n\nprint(f\"AUC: {auc_model:.3f}\")\nprint(f\"95% Confidence Interval for AUC using DeLong method: [{lower_bound:.3f}, {upper_bound:.3f}]\")\n\nAUC: 0.914\n95% Confidence Interval for AUC using DeLong method: [-9969.485, 9971.314]\n\n\nC:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_18272\\717348408.py:13: RuntimeWarning: overflow encountered in long_scalars\n  var_U = (U * (n_positives + n_negatives + 1) * (n_positives + n_negatives - U)) / 12"
  },
  {
    "objectID": "machine-learning/delong_test.html#tính-khoảng-tin-cậy-auc-sử-dụng-phương-pháp-bootstrap",
    "href": "machine-learning/delong_test.html#tính-khoảng-tin-cậy-auc-sử-dụng-phương-pháp-bootstrap",
    "title": "AUC",
    "section": "Tính khoảng tin cậy AUC sử dụng phương pháp Bootstrap",
    "text": "Tính khoảng tin cậy AUC sử dụng phương pháp Bootstrap\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score, roc_curve\n\n\n# Tính AUC cho mô hình ban đầu\nauc_model = roc_auc_score(y_test, y_prob)\n\n# Số lượng lần lấy mẫu (bootstrap iterations)\nn_iterations = 1000\n\n# Số lượng mẫu lấy ra từ dữ liệu ban đầu trong mỗi lần lấy mẫu\nn_size = len(y_test)\n\n# Tạo mảng để lưu kết quả AUC từ các lần lấy mẫu\nauc_scores = []\n\nfor _ in range(n_iterations):\n    # Lấy ngẫu nhiên mẫu từ dữ liệu với replacement\n    indices = np.random.randint(0, n_size, n_size)\n    y_true_bootstrap = y_test[indices]\n    y_prob_bootstrap = y_prob[indices]\n    \n    # Tính AUC cho mẫu lấy ra từ dữ liệu bootstrap\n    auc_score = roc_auc_score(y_true_bootstrap, y_prob_bootstrap)\n    auc_scores.append(auc_score)\n\n# Tính khoảng tin cậy 95% cho AUC\nlower_bound = np.percentile(auc_scores, 2.5)\nupper_bound = np.percentile(auc_scores, 97.5)\n\nprint(f\"AUC: {auc_model:.3f}\")\nprint(f\"95% Confidence Interval for AUC using bootstrap method: [{lower_bound:.3f}, {upper_bound:.3f}]\")\n\nAUC: 0.914\n95% Confidence Interval for AUC using bootstrap method: [0.878, 0.943]"
  },
  {
    "objectID": "machine-learning/delong_test.html#so-sánh-auc-của-hai-mô-hình-máy-học-sử-dụng-kiểm-định-thống-kê-delong",
    "href": "machine-learning/delong_test.html#so-sánh-auc-của-hai-mô-hình-máy-học-sử-dụng-kiểm-định-thống-kê-delong",
    "title": "AUC",
    "section": "So sánh AUC của hai mô hình máy học sử dụng kiểm định thống kê DeLong",
    "text": "So sánh AUC của hai mô hình máy học sử dụng kiểm định thống kê DeLong\nGiả sử AUC của mô hình thứ nhất là (_1) và AUC của mô hình thứ hai là (_2).\nCông thức kiểm định DeLong để so sánh AUC của hai mô hình như sau:\n\\[ U = \\frac{\\text{AUC}_1 - \\text{AUC}_2}{\\sqrt{\\text{Var}(\\text{AUC}_1) + \\text{Var}(\\text{AUC}_2) - 2 \\cdot \\text{Cov}(\\text{AUC}_1, \\text{AUC}_2)}} \\]\nTrong đó: - ((_1)) là phương sai của AUC của mô hình thứ nhất. - ((_2)) là phương sai của AUC của mô hình thứ hai. - ((_1, _2)) là hiệp phương sai giữa AUC của hai mô hình.\n\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nfrom scipy.stats import norm\n\n# Dữ liệu mẫu cho hai mô hình (y_true là nhãn thực tế, y_prob_model1 và y_prob_model2 là xác suất dự đoán của hai mô hình)\nnp.random.seed(42)\ny_true = np.random.randint(0, 2, size=1000)  # Nhãn thực tế (0 hoặc 1)\ny_prob_model1 = np.random.rand(1000)  # Xác suất dự đoán của mô hình thứ nhất\ny_prob_model2 = np.random.rand(1000)  # Xác suất dự đoán của mô hình thứ hai\n\n# Tính AUC cho hai mô hình\nauc_model1 = roc_auc_score(y_true, y_prob_model1)\nauc_model2 = roc_auc_score(y_true, y_prob_model2)\n\n# Tính U-statistic và phương sai của U-statistic\nn_positives = np.sum(y_true)\nn_negatives = len(y_true) - n_positives\nU = n_positives * n_negatives\nvar_U = (U * (n_positives + n_negatives + 1) * (n_positives + n_negatives - U)) / 12\n\n# Tính giá trị Z-score tương ứng với mức đáng tin cậy 95%\nalpha = 0.05\nz_score = norm.ppf(1 - alpha / 2)\n\n# Tính U-score\nU_score = (auc_model1 - auc_model2) / np.sqrt(var_U)\n\n# Tính p-value từ Z-score\np_value = 2 * norm.cdf(-np.abs(U_score))\n\nprint(f\"AUC Model 1: {auc_model1:.3f}\")\nprint(f\"AUC Model 2: {auc_model2:.3f}\")\nprint(f\"U-score: {U_score:.3f}\")\nprint(f\"p-value: {p_value:.3f}\")\n\n# So sánh AUC của hai mô hình\nif p_value &lt; alpha:\n    print(\"Có sự khác biệt đáng kể giữa AUC của hai mô hình.\")\nelse:\n    print(\"Không có sự khác biệt đáng kể giữa AUC của hai mô hình.\")\n\nAUC Model 1: 0.517\nAUC Model 2: 0.507\nU-score: 0.000\np-value: 1.000\nKhông có sự khác biệt đáng kể giữa AUC của hai mô hình.\n\n\nC:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_18272\\3311839127.py:19: RuntimeWarning: overflow encountered in long_scalars\n  var_U = (U * (n_positives + n_negatives + 1) * (n_positives + n_negatives - U)) / 12"
  },
  {
    "objectID": "machine-learning/delong_test.html#so-sánh-auc-của-hai-mô-hình-bằng-bootstrap",
    "href": "machine-learning/delong_test.html#so-sánh-auc-của-hai-mô-hình-bằng-bootstrap",
    "title": "AUC",
    "section": "So sánh AUC của hai mô hình bằng bootstrap",
    "text": "So sánh AUC của hai mô hình bằng bootstrap\n\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\n\n# Tạo dữ liệu mẫu với độ dài chuỗi y_true là 1000\nnp.random.seed(42)\ny_true = np.random.randint(0, 2, size=1000)  # Nhãn thực tế (0 hoặc 1)\ny_prob_model1 = np.random.rand(1000)  # Xác suất dự đoán của mô hình thứ nhất\ny_prob_model2 = np.random.rand(1000)  # Xác suất dự đoán của mô hình thứ hai\n\n# Tính AUC cho hai mô hình\nauc_model1 = roc_auc_score(y_true, y_prob_model1)\nauc_model2 = roc_auc_score(y_true, y_prob_model2)\n\n# Thực hiện bootstrap để tính khoảng tin cậy 95% cho AUC của cả hai mô hình\nn_iterations = 1000  # Số lượng lần lấy mẫu bootstrap\nn_size = len(y_true)  # Số lượng phần tử trong chuỗi y_true\n\nauc_scores_model1 = []\nauc_scores_model2 = []\n\nfor _ in range(n_iterations):\n    # Lấy ngẫu nhiên mẫu từ dữ liệu với replacement\n    indices = np.random.randint(0, n_size, n_size)\n    y_true_bootstrap = y_true[indices]\n    y_prob_bootstrap_model1 = y_prob_model1[indices]\n    y_prob_bootstrap_model2 = y_prob_model2[indices]\n    \n    # Tính AUC cho mẫu lấy ra từ dữ liệu bootstrap cho hai mô hình\n    auc_score_model1 = roc_auc_score(y_true_bootstrap, y_prob_bootstrap_model1)\n    auc_score_model2 = roc_auc_score(y_true_bootstrap, y_prob_bootstrap_model2)\n    \n    auc_scores_model1.append(auc_score_model1)\n    auc_scores_model2.append(auc_score_model2)\n\n# Tính khoảng tin cậy 95% cho AUC cho cả hai mô hình\nlower_bound_model1 = np.percentile(auc_scores_model1, 2.5)\nupper_bound_model1 = np.percentile(auc_scores_model1, 97.5)\n\nlower_bound_model2 = np.percentile(auc_scores_model2, 2.5)\nupper_bound_model2 = np.percentile(auc_scores_model2, 97.5)\n\nprint(f\"AUC Model 1: {auc_model1:.3f} (95% CI: [{lower_bound_model1:.3f}, {upper_bound_model1:.3f}])\")\nprint(f\"AUC Model 2: {auc_model2:.3f} (95% CI: [{lower_bound_model2:.3f}, {upper_bound_model2:.3f}])\")\n\n# So sánh khoảng tin cậy của AUC của hai mô hình\nif lower_bound_model1 &gt; upper_bound_model2 or lower_bound_model2 &gt; upper_bound_model1:\n    print(\"Có sự khác biệt đáng kể giữa AUC của hai mô hình.\")\nelse:\n    print(\"Không có sự khác biệt đáng kể giữa AUC của hai mô hình.\")\n\nAUC Model 1: 0.517 (95% CI: [0.481, 0.551])\nAUC Model 2: 0.507 (95% CI: [0.472, 0.541])\nKhông có sự khác biệt đáng kể giữa AUC của hai mô hình."
  },
  {
    "objectID": "machine-learning/transformer.html",
    "href": "machine-learning/transformer.html",
    "title": "Transformer",
    "section": "",
    "text": "Kiến trúc Transformer là một mô hình học sâu phổ biến được giới thiệu trong bài báo “Attention is All You Need” của Vaswani và đồng nghiệp (2017). Nó đã cách mạng hóa nhiều nhiệm vụ xử lý ngôn ngữ tự nhiên (NLP) và trở thành cơ sở cho các mô hình tiên tiến như BERT và GPT.\nKiến trúc Transformer dựa trên khái niệm self-attention, cho phép mô hình tập trung vào các phần khác nhau của chuỗi đầu vào khi xử lý từng phần tử. Dưới đây là một cái nhìn tổng quan về kiến trúc Transformer:\n\n\n\nKiến trúc Transformer\n\n\n\nNhúng Đầu Vào (Input Embeddings):\n\nChuỗi đầu vào được nhúng thành các biểu diễn liên tục được gọi là nhúng đầu vào.\nMỗi từ hoặc thành phần trong chuỗi đầu vào được biểu diễn bằng một vector mật độ.\n\nMã Hóa Vị Trí (Positional Encoding):\n\nMã hóa vị trí được thêm vào nhúng đầu vào để cung cấp thông tin về thứ tự hoặc vị trí của các từ trong chuỗi.\nĐiều này cho phép mô hình bắt chước thông tin tuần tự, vì kiến trúc Transformer không có kết nối lặp lại.\n\nBộ Mã Hóa (Encoder):\n\nTransformer bao gồm một cấu trúc mã hóa-giải mã (encoder-decoder), nhưng để đơn giản, chúng ta tập trung vào bộ mã hóa.\nBộ mã hóa bao gồm nhiều lớp giống nhau, mỗi lớp bao gồm hai lớp con:\n\nMulti-head Self-Attention:\n\nSelf-attention cho phép mô hình đánh trọng số sự quan trọng của các từ khác nhau trong chuỗi đầu vào khi xử lý một từ cụ thể.\nNó tính toán tổng trọng số của các nhúng từ tất cả các từ, trong đó trọng số được xác định bởi sự tương đồng giữa các từ.\n\nFeed-Forward Neural Network:\n\nA simple feed-forward neural network được áp dụng cho từng vị trí trong chuỗi độc lập.\nNó giúp bắt chước mối quan hệ phi tuyến giữa các từ trong chuỗi.\n\n\n\nBộ Giải Mã (Decoder):\n\nBộ giải mã tương tự như bộ mã hóa nhưng có cơ chế attention bổ sung.\nNó tạo ra chuỗi đầu ra bằng cách chú ý đến các biểu diễn đầu ra của bộ mã hóa và các từ đã được tạo ra trước đó.\n\nCơ Chế Che (Masking):\n\nTrong quá trình huấn luyện, cơ chế che được sử dụng để ngăn mô hình chú ý đến các vị trí trong tương lai.\nĐiều này đảm bảo rằng mỗi vị trí chỉ có thể chú ý đến các vị trí trước đó trong chuỗi đầu vào.\n\nTạo Ra Đầu Ra:\n\nLớp cuối cùng của bộ giải mã tạo ra xác suất đầu ra cho mỗi vị trí trong chuỗi đầu ra.\nCác xác suất này thường được tính bằng cách sử dụng hàm kích hoạt softmax.\n\n\nKiến trúc Transformer có một số lợi thế, như khả năng song song hóa, khả năng bắt chước các phụ thuộc xa, và khả năng tổng quát tốt hơn nhờ self-attention. Nó đã đạt được kết quả tiên tiến trên nhiều nhiệm vụ NLP, bao gồm dịch máy, tóm tắt văn bản và hiểu ngôn ngữ.\n\n\n\n\n\nSelf-attention, còn được gọi là intra-attention hay scaled dot-product attention (tích vô hướng giữa 2 vector), là một cơ chế tính toán trọng số chú ý cho các phần tử trong cùng một chuỗi đầu vào. Nó cho phép mô hình đánh giá mức độ quan trọng của mỗi phần tử trong chuỗi dựa trên mức liên quan của nó đối với các phần tử khác.\n\n\n\nTrong self-attention, mỗi từ trong chuỗi đầu vào được biểu diễn bằng một vector, thông thường được gọi là nhúng hay vector nhúng (embedding vector). Giả sử nhúng từ cho chuỗi đầu vào như sau:\nVí dụ câu như sau: “Con mèo ngồi trên chiếc thảm.”\nĐể áp dụng self-attention, chúng ta trước tiên biểu diễn mỗi từ trong câu thành một vector nhúng. Hãy giả sử chúng ta có các vector nhúng từ sau đây:\nNhúng từ:\n- \"Con\": [0.2, 0.5, -0.3]\n- \"mèo\": [-0.1, 0.7, 0.2]\n- \"ngồi\": [0.4, -0.2, 0.6]\n- \"trên\": [-0.5, 0.3, -0.1]\n- \"chiếc\": [0.2, 0.5, -0.3]\n- \"thảm\": [0.3, 0.1, 0.8]\n- \".\": [0.0, 0.0, 0.0]\nBây giờ, chúng ta tính toán trọng số self-attention cho mỗi từ trong câu. Trong self-attention, mỗi từ được so sánh với tất cả các từ khác để xác định độ quan trọng hoặc liên quan của nó. Quá trình so sánh được thực hiện bằng cách tính tích vô hướng giữa nhúng từ, sau đó áp dụng phép softmax để thu được trọng số chú ý.\nVí dụ, đối với từ “Con,” tích vô hướng được tính toán với nhúng từ của tất cả các từ khác:\nTrọng số Chú ý cho “Con”:\n- \"Con\" so sánh với \"Con\": 0.3\n- \"Con\" so sánh với \"mèo\": 0.1\n- \"Con\" so sánh với \"ngồi\": 0.2\n- \"Con\" so sánh với \"trên\": 0.05\n- \"Con\" so sánh với \"chiếc\": 0.35\n- \"Con\" so sánh với \"thảm\": 0.0\n- \"Con\" so sánh với \".\": 0.0\nCác trọng số chú ý phản ánh sự quan trọng của mỗi từ đối với “Con” dựa trên sự tương đồng ngữ nghĩa hoặc liên quan ngữ cảnh của chúng. Phép softmax đảm bảo rằng các trọng số tổng cộng bằng 1.\nChúng ta lặp lại quá trình này cho mỗi từ trong câu để thu được trọng số self-attention cho toàn bộ câu. Những trọng số chú ý này sau đó có thể được sử dụng để tổng hợp thông tin từ các từ khác nhau và bắt chước các mối quan hệ quan trọng trong câu để tiếp tục xử lý trong mô hình.\n\n\n\n\n\n\nMulti-Head Attention là một phần mở rộng của self-attention cho phép mô hình tập trung vào các khía cạnh khác nhau của chuỗi đầu vào cùng một lúc. Đó là việc áp dụng self-attention nhiều lần song song, mỗi attention head tập trung vào một biểu diễn khác nhau của đầu vào. Bằng cách sử dụng nhiều attention head, mô hình có thể nắm bắt các thông tin khác nhau và học các mẫu đa dạng, nâng cao khả năng hiểu và xử lý các chuỗi phức tạp một cách hiệu quả.\n\n\n\n\nXem xét một câu tiếng Anh: “I love cats.” -&gt; Và chúng ta muốn dịch nó sang tiếng Pháp: “J’adore les chats.”\nGiả sử cả hai câu tiếng Anh và tiếng Pháp đã được nhúng thành các vector như sau:\nNhúng từ tiếng Anh:\n\n“I”: [0.1, 0.2, 0.3]\n“love”: [0.4, 0.5, 0.6]\n“cats”: [0.7, 0.8, 0.9]\n\nNhúng từ tiếng Pháp:\n\n“J’adore”: [0.9, 0.8, 0.7]\n“les”: [0.6, 0.5, 0.4]\n“chats”: [0.3, 0.2, 0.1]\n\nTính toán trọng số\n\nGiả sử chúng ta đang sử dụng cơ chế multi-head attention với 2 attention head. Mỗi head sẽ tập trung vào chuỗi đầu vào tiếng Anh (nguồn) và chuỗi đầu vào tiếng Pháp (đích) riêng biệt.\nVới mỗi attention head, chúng ta sẽ tính toán trọng số attention cho cả chuỗi đầu vào tiếng Anh và tiếng Pháp. Các trọng số attention xác định mức độ quan trọng của mỗi từ trong chuỗi nguồn liên quan đến các từ trong chuỗi đích.\nVí dụ,\n\nVới attention head đầu tiên, chúng ta tính toán trọng số attention cho chuỗi đầu vào tiếng Anh:\nAttention_scores_source_head1 = softmax(dot_product(english_source_embeddings, [french_target_embedding1, french_target_embedding2, french_target_embedding3]))\nTương tự, chúng ta tính toán trọng số attention cho chuỗi đích tiếng Pháp:\nAttention_scores_target_head1 = softmax(dot_product(french_target_embeddings, [english_source_embedding1, english_source_embedding2, english_source_embedding3]))\nLặp lại các bước trên cho attention head tiếp theo, kết quả sẽ được các attention score cho cả chuỗi nguồn và chuỗi đích.\nSau khi có các trọng số attention, chúng ta áp dụng chúng vào nhúng tương ứng để có tổng có trọng số cho mỗi chuỗi.\nVí dụ, đối với chuỗi nguồn tiếng Anh và attention head đầu tiên:\nWeighted_sum_source_head1 = attention_score1 * english_source_embedding1 + attention_score2 * english_source_embedding2 + attention_score3 * english_source_embedding3\nTương tự, đối với chuỗi đích tiếng Pháp và attention head đầu tiên:\nWeighted_sum_target_head1 = attention_score1 * french_target_embedding1 + attention_score2 * french_target_embedding2 + attention_score3 * french_target_embedding3\nChúng ta lặp lại các bước trên cho attention head thứ hai.\nCuối cùng, chúng ta nối các đầu ra từ mỗi attention head và thông qua một phép biến đổi tuyến tính để có đầu ra multi-head attention cuối cùng.\nNhư vậy, cơ chế multi-head attention cho phép mô hình nắm bắt các thông tin và mối quan hệ khác nhau giữa chuỗi nguồn và chuỗi đích, tăng khả năng dịch giữa các ngôn ngữ một cách chính xác.\n\n\n\n\nimport torch\nimport torch.nn as nn\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, embed_dim, num_heads):\n        super(MultiHeadAttention, self).__init__()\n        \n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // num_heads\n        \n        self.query_projection = nn.Linear(embed_dim, embed_dim)\n        self.key_projection = nn.Linear(embed_dim, embed_dim)\n        self.value_projection = nn.Linear(embed_dim, embed_dim)\n        self.output_projection = nn.Linear(embed_dim, embed_dim)\n        \n    def forward(self, query, key, value):\n        batch_size = query.size(0)\n        \n        # Apply linear projections for query, key, and value\n        query = self.query_projection(query)\n        key = self.key_projection(key)\n        value = self.value_projection(value)\n        \n        # Reshape query, key, and value to split heads\n        query = query.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n        key = key.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n        value = value.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n        \n        # Compute attention scores\n        scores = torch.matmul(query, key.transpose(-2, -1))\n        scores = scores / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))\n        attention_weights = torch.softmax(scores, dim=-1)\n        \n        # Apply attention weights to value\n        attended_values = torch.matmul(attention_weights, value)\n        \n        # Reshape and concatenate attended values\n        attended_values = attended_values.transpose(1, 2).contiguous().view(batch_size, -1, self.embed_dim)\n        \n        # Apply linear projection for output\n        output = self.output_projection(attended_values)\n        \n        return output\n\n\n\n\n\n\n\nPhép mã hóa vị trí (Positional Encoding) là một kỹ thuật được sử dụng trong các mô hình dựa trên chuỗi, đặc biệt là trong kiến trúc Transformer, để đưa thông tin về vị trí tương đối của các yếu tố trong chuỗi đầu vào. Nó giải quyết vấn đề rằng tự chú ý (self-attention) và các cơ chế chú ý khác trong các mô hình này không ngầm định mã hóa thông tin về vị trí.\nTrong các nhiệm vụ xử lý ngôn ngữ tự nhiên, thứ tự của các từ trong một câu mang ý nghĩa và ngữ cảnh quan trọng. Tuy nhiên, mô hình Transformer xử lý chuỗi đầu vào theo cách song song, không rõ ràng ghi nhận thứ tự tuần tự. Phép mã hóa vị trí giúp mô hình phân biệt giữa các yếu tố ở các vị trí khác nhau trong chuỗi.\nMã hóa vị trí được thêm vào nhúng đầu vào của chuỗi trước khi đưa chúng vào mô hình Transformer. Thông thường, điều này được thực hiện bằng cách kết hợp các hàm sin-cos với các nhúng đầu vào. Mỗi chiều của mã hóa vị trí đại diện cho một vị trí cụ thể trong chuỗi.\nSự lựa chọn các hàm sin-cos cho phép mô hình dễ dàng mở rộng cho các độ dài chuỗi dài hơn so với những gì mô hình đã được huấn luyện. Tần số của các hàm sin-cos tuân theo một cấp số học, cho phép mô hình học để chú ý đến các vị trí khác nhau với các tỷ lệ khác nhau.\nBằng cách thêm mã hóa vị trí vào nhúng đầu vào, mô hình Transformer có thể hiệu quả nắm bắt thứ tự và vị trí tương đối của các yếu tố trong chuỗi. Điều này giúp mô hình hiểu các phụ thuộc và mối quan hệ giữa các vị trí khác nhau và cho phép thực hiện các nhiệm vụ yêu cầu xử lý thông tin tuần tự, chẳng hạn như dịch máy hoặc hiểu ngôn ngữ.\n\n\n\n\nGiả sử chúng ta có một chuỗi đầu vào gồm ba từ: [“Tôi”, “yêu”, “mèo”].\nMỗi từ sẽ được biểu diễn bằng một vector nhúng từ, nắm bắt ý nghĩa ngữ nghĩa của nó. Hãy giả định các vector nhúng từ như sau:\n\n“Tôi”: [0.2, 0.3, -0.1]\n“yêu”: [-0.5, 0.7, 0.2]\n“mèo”: [0.7, 0.8, 0.9]\n\nĐể tích hợp thông tin về vị trí, chúng ta sử dụng mã hóa vị trí. Trong ví dụ này, chúng ta sẽ sử dụng các hàm sin và cos để tạo các vector mã hóa vị trí.\nGiả sử chiều nhúng là 3, các vector mã hóa vị trí sẽ được tính như sau:\nCho vị trí 0 (từ đầu tiên): - PE(0) = [sin(0/10000^0), cos(0/10000^0), sin(0/10000^0)]\nCho vị trí 1 (từ thứ hai): - PE(1) = [sin(1/10000^1), cos(1/10000^1), sin(1/10000^1)]\nCho vị trí 2 (từ thứ ba): - PE(2) = [sin(2/10000^0), cos(2/10000^0), sin(2/10000^0)]\nVì sin(0) = 0, sin(1) = 0.8415, sin(2) = 0.9093, cos(0) = 1, cos(1) = 0.5403, cos(2) = -0.4161.\nNên, các vector mã hóa vị trí là:\nPE(0) = [0, 1, 0] PE(1) = [0.8415, 0.5403, 0.8415] PE(2) = [0.9093, -0.4161, 0.9093]\nĐể tích hợp mã hóa vị trí, chúng ta cộng vector mã hóa vị trí tương ứng vào mỗi vector nhúng từ:\n\nTừ “Tôi” với mã hóa vị trí: [0.2, 0.3, -0.1] + [0, 1, 0] = [0.2, 1.3, -0.1]\nTừ “yêu” với mã hóa vị trí: [-0.5, 0.7, 0.2] + [0.8415, 0.5403, 0.8415] =\n\n[0.3415, 1.2403, 1.0415] - Từ “mèo” với mã hóa vị trí: [0.7, 0.8, 0.9] + [0.9093, -0.4161, 0.9093] = [1.6093, 0.3839, 1.8093]\nBằng cách cộng các vector mã hóa vị trí vào các vector nhúng từ, chúng ta giới thiệu thông tin về vị trí tương đối của các từ trong chuỗi đầu vào. Điều này cho phép mô hình Transformer nắm bắt thứ tự tuần tự và các phụ thuộc giữa các từ, điều quan trọng cho các nhiệm vụ như dịch máy hoặc phân tích cảm xúc.\n\n\n\n\nLayer Normalization là một kỹ thuật được sử dụng trong các mô hình học sâu để chuẩn hóa các kích hoạt (kết quả chuyển đổi đầu vào thành đầu ra bằng hàm kích hoạt - tạm gọi là các kích hoạt) của các đơn vị trong một lớp. Nó giải quyết vấn đề của sự thay đổi phân phối đầu vào của lớp trong quá trình huấn luyện, gây khó khăn cho quá trình học.\nCông thức cho Layer Normalization có thể được biểu diễn như sau:\noutput = scale * (input - mean) / sqrt(variance + epsilon) + bias\n\nỞ đây, đầu vào đại diện cho các kích hoạt đầu vào của một lớp, trung bình và phương sai đại diện cho giá trị trung bình và phương sai được tính theo chiều đầu vào, epsilon là một hằng số nhỏ được thêm vào để đảm bảo tính ổn định số học, và scale và bias là các tham số có thể học giúp mô hình điều chỉnh và dịch chuyển các kích hoạt đã được chuẩn hóa.\nLayer Normalization được áp dụng độc lập cho mỗi lô dữ liệu (batch), điều này làm cho nó phù hợp cho các nhiệm vụ với kích thước lô nhỏ. Nó đã được chứng minh là hiệu quả trong ổn định quá trình huấn luyện, tăng tốc quá trình hội tụ và cải thiện hiệu suất tổng quát của các mô hình học sâu.\nTổng quát, Layer Normalization giúp giảm sự phụ thuộc vào tỷ lệ của các kích hoạt đầu vào, thúc đẩy việc truyền gradient ổn định và cải thiện động học huấn luyện tổng thể (overall training dynamics - gồm learning rate, gradient, loss rate) của mạng neural. Nó đã được sử dụng rộng rãi trong các lĩnh vực khác nhau, bao gồm xử lý ngôn ngữ tự nhiên, thị giác máy tính và nhận dạng giọng nói.\n\n\n\nGiả sử chúng ta có một câu: “Tôi thích chơi bóng đá.”\nTrong mô hình ngôn ngữ, mục tiêu là dự đoán từ tiếp theo trong ngữ cảnh đã cho. Tuy nhiên, trong quá trình huấn luyện, chúng ta thường không muốn cho mô hình truy cập vào các từ trong tương lai vì nó có thể dẫn đến rò rỉ dữ liệu và dự đoán không thực tế. Vì vậy, chế che được áp dụng.\nĐể áp dụng cơ chế che, thường được ký hiệu là [MASK], để thay thế một số từ trong chuỗi đầu vào trong quá trình huấn luyện. Trong trường hợp này, chúng ta có thể ngẫu nhiên che một số từ trong câu, dẫn đến:\nCâu Đầu Vào (có cơ chế che): “Tôi thích chơi [MASK] bóng đá.”\nBây giờ, trong quá trình huấn luyện, mục tiêu của mô hình là dự đoán từ bị che dựa trên ngữ cảnh xung quanh. Nó học cách hiểu cấu trúc câu, ý nghĩa và sự phụ thuộc giữa các từ để đưa ra dự đoán chính xác. Mô hình nhận chuỗi đầu vào đã được chỉnh sửa (thêm [MASK]) và cố gắng dự đoán bản gốc, không bị che, ở vị trí đã được che.\nTrong quá trình huấn luyện hoặc đánh giá, cơ chế che không được sử dụng và mô hình được cung cấp với toàn bộ chuỗi đầu vào. Nó có thể tạo ra dự đoán cho từ tiếp theo trong chuỗi dựa trên kiến thức đã học từ quá trình huấn luyện.\nCơ chế che giúp mô hình tổng quát tốt và xử lý các trường hợp mà nó gặp phải các từ chưa được nhìn thấy hoặc thiếu. Nó khuyến khích mô hình dựa vào ngữ cảnh có sẵn để đưa ra dự đoán chính xác và cải thiện khả năng hiểu cấu trúc câu."
  },
  {
    "objectID": "machine-learning/transformer.html#transformer-architecture",
    "href": "machine-learning/transformer.html#transformer-architecture",
    "title": "Transformer",
    "section": "",
    "text": "Kiến trúc Transformer là một mô hình học sâu phổ biến được giới thiệu trong bài báo “Attention is All You Need” của Vaswani và đồng nghiệp (2017). Nó đã cách mạng hóa nhiều nhiệm vụ xử lý ngôn ngữ tự nhiên (NLP) và trở thành cơ sở cho các mô hình tiên tiến như BERT và GPT.\nKiến trúc Transformer dựa trên khái niệm self-attention, cho phép mô hình tập trung vào các phần khác nhau của chuỗi đầu vào khi xử lý từng phần tử. Dưới đây là một cái nhìn tổng quan về kiến trúc Transformer:\n\n\n\nKiến trúc Transformer\n\n\n\nNhúng Đầu Vào (Input Embeddings):\n\nChuỗi đầu vào được nhúng thành các biểu diễn liên tục được gọi là nhúng đầu vào.\nMỗi từ hoặc thành phần trong chuỗi đầu vào được biểu diễn bằng một vector mật độ.\n\nMã Hóa Vị Trí (Positional Encoding):\n\nMã hóa vị trí được thêm vào nhúng đầu vào để cung cấp thông tin về thứ tự hoặc vị trí của các từ trong chuỗi.\nĐiều này cho phép mô hình bắt chước thông tin tuần tự, vì kiến trúc Transformer không có kết nối lặp lại.\n\nBộ Mã Hóa (Encoder):\n\nTransformer bao gồm một cấu trúc mã hóa-giải mã (encoder-decoder), nhưng để đơn giản, chúng ta tập trung vào bộ mã hóa.\nBộ mã hóa bao gồm nhiều lớp giống nhau, mỗi lớp bao gồm hai lớp con:\n\nMulti-head Self-Attention:\n\nSelf-attention cho phép mô hình đánh trọng số sự quan trọng của các từ khác nhau trong chuỗi đầu vào khi xử lý một từ cụ thể.\nNó tính toán tổng trọng số của các nhúng từ tất cả các từ, trong đó trọng số được xác định bởi sự tương đồng giữa các từ.\n\nFeed-Forward Neural Network:\n\nA simple feed-forward neural network được áp dụng cho từng vị trí trong chuỗi độc lập.\nNó giúp bắt chước mối quan hệ phi tuyến giữa các từ trong chuỗi.\n\n\n\nBộ Giải Mã (Decoder):\n\nBộ giải mã tương tự như bộ mã hóa nhưng có cơ chế attention bổ sung.\nNó tạo ra chuỗi đầu ra bằng cách chú ý đến các biểu diễn đầu ra của bộ mã hóa và các từ đã được tạo ra trước đó.\n\nCơ Chế Che (Masking):\n\nTrong quá trình huấn luyện, cơ chế che được sử dụng để ngăn mô hình chú ý đến các vị trí trong tương lai.\nĐiều này đảm bảo rằng mỗi vị trí chỉ có thể chú ý đến các vị trí trước đó trong chuỗi đầu vào.\n\nTạo Ra Đầu Ra:\n\nLớp cuối cùng của bộ giải mã tạo ra xác suất đầu ra cho mỗi vị trí trong chuỗi đầu ra.\nCác xác suất này thường được tính bằng cách sử dụng hàm kích hoạt softmax.\n\n\nKiến trúc Transformer có một số lợi thế, như khả năng song song hóa, khả năng bắt chước các phụ thuộc xa, và khả năng tổng quát tốt hơn nhờ self-attention. Nó đã đạt được kết quả tiên tiến trên nhiều nhiệm vụ NLP, bao gồm dịch máy, tóm tắt văn bản và hiểu ngôn ngữ."
  },
  {
    "objectID": "machine-learning/transformer.html#self-attention",
    "href": "machine-learning/transformer.html#self-attention",
    "title": "Transformer",
    "section": "",
    "text": "Self-attention, còn được gọi là intra-attention hay scaled dot-product attention (tích vô hướng giữa 2 vector), là một cơ chế tính toán trọng số chú ý cho các phần tử trong cùng một chuỗi đầu vào. Nó cho phép mô hình đánh giá mức độ quan trọng của mỗi phần tử trong chuỗi dựa trên mức liên quan của nó đối với các phần tử khác.\n\n\n\nTrong self-attention, mỗi từ trong chuỗi đầu vào được biểu diễn bằng một vector, thông thường được gọi là nhúng hay vector nhúng (embedding vector). Giả sử nhúng từ cho chuỗi đầu vào như sau:\nVí dụ câu như sau: “Con mèo ngồi trên chiếc thảm.”\nĐể áp dụng self-attention, chúng ta trước tiên biểu diễn mỗi từ trong câu thành một vector nhúng. Hãy giả sử chúng ta có các vector nhúng từ sau đây:\nNhúng từ:\n- \"Con\": [0.2, 0.5, -0.3]\n- \"mèo\": [-0.1, 0.7, 0.2]\n- \"ngồi\": [0.4, -0.2, 0.6]\n- \"trên\": [-0.5, 0.3, -0.1]\n- \"chiếc\": [0.2, 0.5, -0.3]\n- \"thảm\": [0.3, 0.1, 0.8]\n- \".\": [0.0, 0.0, 0.0]\nBây giờ, chúng ta tính toán trọng số self-attention cho mỗi từ trong câu. Trong self-attention, mỗi từ được so sánh với tất cả các từ khác để xác định độ quan trọng hoặc liên quan của nó. Quá trình so sánh được thực hiện bằng cách tính tích vô hướng giữa nhúng từ, sau đó áp dụng phép softmax để thu được trọng số chú ý.\nVí dụ, đối với từ “Con,” tích vô hướng được tính toán với nhúng từ của tất cả các từ khác:\nTrọng số Chú ý cho “Con”:\n- \"Con\" so sánh với \"Con\": 0.3\n- \"Con\" so sánh với \"mèo\": 0.1\n- \"Con\" so sánh với \"ngồi\": 0.2\n- \"Con\" so sánh với \"trên\": 0.05\n- \"Con\" so sánh với \"chiếc\": 0.35\n- \"Con\" so sánh với \"thảm\": 0.0\n- \"Con\" so sánh với \".\": 0.0\nCác trọng số chú ý phản ánh sự quan trọng của mỗi từ đối với “Con” dựa trên sự tương đồng ngữ nghĩa hoặc liên quan ngữ cảnh của chúng. Phép softmax đảm bảo rằng các trọng số tổng cộng bằng 1.\nChúng ta lặp lại quá trình này cho mỗi từ trong câu để thu được trọng số self-attention cho toàn bộ câu. Những trọng số chú ý này sau đó có thể được sử dụng để tổng hợp thông tin từ các từ khác nhau và bắt chước các mối quan hệ quan trọng trong câu để tiếp tục xử lý trong mô hình."
  },
  {
    "objectID": "machine-learning/transformer.html#multi-head-attention",
    "href": "machine-learning/transformer.html#multi-head-attention",
    "title": "Transformer",
    "section": "",
    "text": "Multi-Head Attention là một phần mở rộng của self-attention cho phép mô hình tập trung vào các khía cạnh khác nhau của chuỗi đầu vào cùng một lúc. Đó là việc áp dụng self-attention nhiều lần song song, mỗi attention head tập trung vào một biểu diễn khác nhau của đầu vào. Bằng cách sử dụng nhiều attention head, mô hình có thể nắm bắt các thông tin khác nhau và học các mẫu đa dạng, nâng cao khả năng hiểu và xử lý các chuỗi phức tạp một cách hiệu quả.\n\n\n\n\nXem xét một câu tiếng Anh: “I love cats.” -&gt; Và chúng ta muốn dịch nó sang tiếng Pháp: “J’adore les chats.”\nGiả sử cả hai câu tiếng Anh và tiếng Pháp đã được nhúng thành các vector như sau:\nNhúng từ tiếng Anh:\n\n“I”: [0.1, 0.2, 0.3]\n“love”: [0.4, 0.5, 0.6]\n“cats”: [0.7, 0.8, 0.9]\n\nNhúng từ tiếng Pháp:\n\n“J’adore”: [0.9, 0.8, 0.7]\n“les”: [0.6, 0.5, 0.4]\n“chats”: [0.3, 0.2, 0.1]\n\nTính toán trọng số\n\nGiả sử chúng ta đang sử dụng cơ chế multi-head attention với 2 attention head. Mỗi head sẽ tập trung vào chuỗi đầu vào tiếng Anh (nguồn) và chuỗi đầu vào tiếng Pháp (đích) riêng biệt.\nVới mỗi attention head, chúng ta sẽ tính toán trọng số attention cho cả chuỗi đầu vào tiếng Anh và tiếng Pháp. Các trọng số attention xác định mức độ quan trọng của mỗi từ trong chuỗi nguồn liên quan đến các từ trong chuỗi đích.\nVí dụ,\n\nVới attention head đầu tiên, chúng ta tính toán trọng số attention cho chuỗi đầu vào tiếng Anh:\nAttention_scores_source_head1 = softmax(dot_product(english_source_embeddings, [french_target_embedding1, french_target_embedding2, french_target_embedding3]))\nTương tự, chúng ta tính toán trọng số attention cho chuỗi đích tiếng Pháp:\nAttention_scores_target_head1 = softmax(dot_product(french_target_embeddings, [english_source_embedding1, english_source_embedding2, english_source_embedding3]))\nLặp lại các bước trên cho attention head tiếp theo, kết quả sẽ được các attention score cho cả chuỗi nguồn và chuỗi đích.\nSau khi có các trọng số attention, chúng ta áp dụng chúng vào nhúng tương ứng để có tổng có trọng số cho mỗi chuỗi.\nVí dụ, đối với chuỗi nguồn tiếng Anh và attention head đầu tiên:\nWeighted_sum_source_head1 = attention_score1 * english_source_embedding1 + attention_score2 * english_source_embedding2 + attention_score3 * english_source_embedding3\nTương tự, đối với chuỗi đích tiếng Pháp và attention head đầu tiên:\nWeighted_sum_target_head1 = attention_score1 * french_target_embedding1 + attention_score2 * french_target_embedding2 + attention_score3 * french_target_embedding3\nChúng ta lặp lại các bước trên cho attention head thứ hai.\nCuối cùng, chúng ta nối các đầu ra từ mỗi attention head và thông qua một phép biến đổi tuyến tính để có đầu ra multi-head attention cuối cùng.\nNhư vậy, cơ chế multi-head attention cho phép mô hình nắm bắt các thông tin và mối quan hệ khác nhau giữa chuỗi nguồn và chuỗi đích, tăng khả năng dịch giữa các ngôn ngữ một cách chính xác.\n\n\n\n\nimport torch\nimport torch.nn as nn\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, embed_dim, num_heads):\n        super(MultiHeadAttention, self).__init__()\n        \n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // num_heads\n        \n        self.query_projection = nn.Linear(embed_dim, embed_dim)\n        self.key_projection = nn.Linear(embed_dim, embed_dim)\n        self.value_projection = nn.Linear(embed_dim, embed_dim)\n        self.output_projection = nn.Linear(embed_dim, embed_dim)\n        \n    def forward(self, query, key, value):\n        batch_size = query.size(0)\n        \n        # Apply linear projections for query, key, and value\n        query = self.query_projection(query)\n        key = self.key_projection(key)\n        value = self.value_projection(value)\n        \n        # Reshape query, key, and value to split heads\n        query = query.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n        key = key.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n        value = value.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n        \n        # Compute attention scores\n        scores = torch.matmul(query, key.transpose(-2, -1))\n        scores = scores / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))\n        attention_weights = torch.softmax(scores, dim=-1)\n        \n        # Apply attention weights to value\n        attended_values = torch.matmul(attention_weights, value)\n        \n        # Reshape and concatenate attended values\n        attended_values = attended_values.transpose(1, 2).contiguous().view(batch_size, -1, self.embed_dim)\n        \n        # Apply linear projection for output\n        output = self.output_projection(attended_values)\n        \n        return output"
  },
  {
    "objectID": "machine-learning/transformer.html#positional-encoding",
    "href": "machine-learning/transformer.html#positional-encoding",
    "title": "Transformer",
    "section": "",
    "text": "Phép mã hóa vị trí (Positional Encoding) là một kỹ thuật được sử dụng trong các mô hình dựa trên chuỗi, đặc biệt là trong kiến trúc Transformer, để đưa thông tin về vị trí tương đối của các yếu tố trong chuỗi đầu vào. Nó giải quyết vấn đề rằng tự chú ý (self-attention) và các cơ chế chú ý khác trong các mô hình này không ngầm định mã hóa thông tin về vị trí.\nTrong các nhiệm vụ xử lý ngôn ngữ tự nhiên, thứ tự của các từ trong một câu mang ý nghĩa và ngữ cảnh quan trọng. Tuy nhiên, mô hình Transformer xử lý chuỗi đầu vào theo cách song song, không rõ ràng ghi nhận thứ tự tuần tự. Phép mã hóa vị trí giúp mô hình phân biệt giữa các yếu tố ở các vị trí khác nhau trong chuỗi.\nMã hóa vị trí được thêm vào nhúng đầu vào của chuỗi trước khi đưa chúng vào mô hình Transformer. Thông thường, điều này được thực hiện bằng cách kết hợp các hàm sin-cos với các nhúng đầu vào. Mỗi chiều của mã hóa vị trí đại diện cho một vị trí cụ thể trong chuỗi.\nSự lựa chọn các hàm sin-cos cho phép mô hình dễ dàng mở rộng cho các độ dài chuỗi dài hơn so với những gì mô hình đã được huấn luyện. Tần số của các hàm sin-cos tuân theo một cấp số học, cho phép mô hình học để chú ý đến các vị trí khác nhau với các tỷ lệ khác nhau.\nBằng cách thêm mã hóa vị trí vào nhúng đầu vào, mô hình Transformer có thể hiệu quả nắm bắt thứ tự và vị trí tương đối của các yếu tố trong chuỗi. Điều này giúp mô hình hiểu các phụ thuộc và mối quan hệ giữa các vị trí khác nhau và cho phép thực hiện các nhiệm vụ yêu cầu xử lý thông tin tuần tự, chẳng hạn như dịch máy hoặc hiểu ngôn ngữ.\n\n\n\n\nGiả sử chúng ta có một chuỗi đầu vào gồm ba từ: [“Tôi”, “yêu”, “mèo”].\nMỗi từ sẽ được biểu diễn bằng một vector nhúng từ, nắm bắt ý nghĩa ngữ nghĩa của nó. Hãy giả định các vector nhúng từ như sau:\n\n“Tôi”: [0.2, 0.3, -0.1]\n“yêu”: [-0.5, 0.7, 0.2]\n“mèo”: [0.7, 0.8, 0.9]\n\nĐể tích hợp thông tin về vị trí, chúng ta sử dụng mã hóa vị trí. Trong ví dụ này, chúng ta sẽ sử dụng các hàm sin và cos để tạo các vector mã hóa vị trí.\nGiả sử chiều nhúng là 3, các vector mã hóa vị trí sẽ được tính như sau:\nCho vị trí 0 (từ đầu tiên): - PE(0) = [sin(0/10000^0), cos(0/10000^0), sin(0/10000^0)]\nCho vị trí 1 (từ thứ hai): - PE(1) = [sin(1/10000^1), cos(1/10000^1), sin(1/10000^1)]\nCho vị trí 2 (từ thứ ba): - PE(2) = [sin(2/10000^0), cos(2/10000^0), sin(2/10000^0)]\nVì sin(0) = 0, sin(1) = 0.8415, sin(2) = 0.9093, cos(0) = 1, cos(1) = 0.5403, cos(2) = -0.4161.\nNên, các vector mã hóa vị trí là:\nPE(0) = [0, 1, 0] PE(1) = [0.8415, 0.5403, 0.8415] PE(2) = [0.9093, -0.4161, 0.9093]\nĐể tích hợp mã hóa vị trí, chúng ta cộng vector mã hóa vị trí tương ứng vào mỗi vector nhúng từ:\n\nTừ “Tôi” với mã hóa vị trí: [0.2, 0.3, -0.1] + [0, 1, 0] = [0.2, 1.3, -0.1]\nTừ “yêu” với mã hóa vị trí: [-0.5, 0.7, 0.2] + [0.8415, 0.5403, 0.8415] =\n\n[0.3415, 1.2403, 1.0415] - Từ “mèo” với mã hóa vị trí: [0.7, 0.8, 0.9] + [0.9093, -0.4161, 0.9093] = [1.6093, 0.3839, 1.8093]\nBằng cách cộng các vector mã hóa vị trí vào các vector nhúng từ, chúng ta giới thiệu thông tin về vị trí tương đối của các từ trong chuỗi đầu vào. Điều này cho phép mô hình Transformer nắm bắt thứ tự tuần tự và các phụ thuộc giữa các từ, điều quan trọng cho các nhiệm vụ như dịch máy hoặc phân tích cảm xúc."
  },
  {
    "objectID": "machine-learning/transformer.html#layer-normalization",
    "href": "machine-learning/transformer.html#layer-normalization",
    "title": "Transformer",
    "section": "",
    "text": "Layer Normalization là một kỹ thuật được sử dụng trong các mô hình học sâu để chuẩn hóa các kích hoạt (kết quả chuyển đổi đầu vào thành đầu ra bằng hàm kích hoạt - tạm gọi là các kích hoạt) của các đơn vị trong một lớp. Nó giải quyết vấn đề của sự thay đổi phân phối đầu vào của lớp trong quá trình huấn luyện, gây khó khăn cho quá trình học.\nCông thức cho Layer Normalization có thể được biểu diễn như sau:\noutput = scale * (input - mean) / sqrt(variance + epsilon) + bias\n\nỞ đây, đầu vào đại diện cho các kích hoạt đầu vào của một lớp, trung bình và phương sai đại diện cho giá trị trung bình và phương sai được tính theo chiều đầu vào, epsilon là một hằng số nhỏ được thêm vào để đảm bảo tính ổn định số học, và scale và bias là các tham số có thể học giúp mô hình điều chỉnh và dịch chuyển các kích hoạt đã được chuẩn hóa.\nLayer Normalization được áp dụng độc lập cho mỗi lô dữ liệu (batch), điều này làm cho nó phù hợp cho các nhiệm vụ với kích thước lô nhỏ. Nó đã được chứng minh là hiệu quả trong ổn định quá trình huấn luyện, tăng tốc quá trình hội tụ và cải thiện hiệu suất tổng quát của các mô hình học sâu.\nTổng quát, Layer Normalization giúp giảm sự phụ thuộc vào tỷ lệ của các kích hoạt đầu vào, thúc đẩy việc truyền gradient ổn định và cải thiện động học huấn luyện tổng thể (overall training dynamics - gồm learning rate, gradient, loss rate) của mạng neural. Nó đã được sử dụng rộng rãi trong các lĩnh vực khác nhau, bao gồm xử lý ngôn ngữ tự nhiên, thị giác máy tính và nhận dạng giọng nói."
  },
  {
    "objectID": "machine-learning/transformer.html#masking",
    "href": "machine-learning/transformer.html#masking",
    "title": "Transformer",
    "section": "",
    "text": "Giả sử chúng ta có một câu: “Tôi thích chơi bóng đá.”\nTrong mô hình ngôn ngữ, mục tiêu là dự đoán từ tiếp theo trong ngữ cảnh đã cho. Tuy nhiên, trong quá trình huấn luyện, chúng ta thường không muốn cho mô hình truy cập vào các từ trong tương lai vì nó có thể dẫn đến rò rỉ dữ liệu và dự đoán không thực tế. Vì vậy, chế che được áp dụng.\nĐể áp dụng cơ chế che, thường được ký hiệu là [MASK], để thay thế một số từ trong chuỗi đầu vào trong quá trình huấn luyện. Trong trường hợp này, chúng ta có thể ngẫu nhiên che một số từ trong câu, dẫn đến:\nCâu Đầu Vào (có cơ chế che): “Tôi thích chơi [MASK] bóng đá.”\nBây giờ, trong quá trình huấn luyện, mục tiêu của mô hình là dự đoán từ bị che dựa trên ngữ cảnh xung quanh. Nó học cách hiểu cấu trúc câu, ý nghĩa và sự phụ thuộc giữa các từ để đưa ra dự đoán chính xác. Mô hình nhận chuỗi đầu vào đã được chỉnh sửa (thêm [MASK]) và cố gắng dự đoán bản gốc, không bị che, ở vị trí đã được che.\nTrong quá trình huấn luyện hoặc đánh giá, cơ chế che không được sử dụng và mô hình được cung cấp với toàn bộ chuỗi đầu vào. Nó có thể tạo ra dự đoán cho từ tiếp theo trong chuỗi dựa trên kiến thức đã học từ quá trình huấn luyện.\nCơ chế che giúp mô hình tổng quát tốt và xử lý các trường hợp mà nó gặp phải các từ chưa được nhìn thấy hoặc thiếu. Nó khuyến khích mô hình dựa vào ngữ cảnh có sẵn để đưa ra dự đoán chính xác và cải thiện khả năng hiểu cấu trúc câu."
  },
  {
    "objectID": "quarto-workflows/browser.html",
    "href": "quarto-workflows/browser.html",
    "title": "From the Browser",
    "section": "",
    "text": "A workflow from the browser if good for getting started (since you do not need to install additional software) and for making small contributions, but is definitely limited. Once you feel comfortable here, you can move to a different setup.\nHere’s an example of editing content on an existing page."
  },
  {
    "objectID": "quarto-workflows/browser.html#edit-content-on-an-existing-page",
    "href": "quarto-workflows/browser.html#edit-content-on-an-existing-page",
    "title": "From the Browser",
    "section": "Edit content on an existing page",
    "text": "Edit content on an existing page\nLet’s change the date on the home page of this website.\nIn your repository, navigate to index.md. Then, click the pencil icon in the top right to edit directly.\n\n\n\n\n\nWe are now in the “Edit file” tab of the editor, where we can make modifications. Let’s change the date to today’s date. Click the “Preview” tab to see your changes. You can even check the “Show diff” box on the right side to see the changes you’ve made.\n\n\n\n\n\nWhile you’re here, see if there are additional changes to the text you’d like to make. Maybe changing the title or author at the top, or for the main text on the home page of the website.\nOur index.md file is written in Markdown, which enables you to make simple text formatting. As you go back and forth from “Edit file” to “Preview”, notice the patterns of how the Markdown text looks when it is as source (“Edit file”) and when it is formatted (“Preview”). For example, in Markdown, you can make text as a header with # symbols, bold or italic with * symbols, and hyperlinks with [](). Notice that spacing is important: for example, there are carriage returns (when you hit the “return” key) before any bullet points. You can learn the short list of Markdown rules here: https://quarto.org/docs/authoring/markdown-basics."
  },
  {
    "objectID": "quarto-workflows/browser.html#commit-and-publish",
    "href": "quarto-workflows/browser.html#commit-and-publish",
    "title": "From the Browser",
    "section": "Commit and publish",
    "text": "Commit and publish\nCommit your changes by scrolling to the bottom of the page and writing a commit message - a note to yourself and others about what changes you made. Write your commit message and then click the green “Commit changes” button.\n\n\n\n\n\nNow, click back to the main page of your GitHub repository. You should see the orange dot confirming your website is published. You’ll have to wait for the GitHub Action to tell quarto to build your site for you to see the update, but it will be there!"
  },
  {
    "objectID": "quarto-workflows/browser.html#limitations",
    "href": "quarto-workflows/browser.html#limitations",
    "title": "From the Browser",
    "section": "Limitations",
    "text": "Limitations\nWhile awesome that we can edit using GitHub directly from the browser, there are obvious limitations. One is that to see your edits show up in your book, you have to publish using the GitHub Action. This is slow. Another limitation is that we can only work on one file at a time and commit them each separately, which also is slow. Using additional software can make things much better, as we explore in subsequent chapters."
  },
  {
    "objectID": "quarto-workflows/rstudio.html",
    "href": "quarto-workflows/rstudio.html",
    "title": "From RStudio",
    "section": "",
    "text": "The RStudio software (called an IDE, integrated development environment) is an excellent way to edit files and interface with GitHub. Plus, as it is made by the same folks who make Quarto, it has many integrated features for streamlining your workflow with Quarto, including how it previews your edits and provides debugging support for yaml! Quarto's RStudio tutorials has great instructions on getting started with RStudio, including computations and authoring.\nHere is what you’ll need to do to set up and use RStudio with Quarto."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#setup",
    "href": "quarto-workflows/rstudio.html#setup",
    "title": "From RStudio",
    "section": "Setup",
    "text": "Setup\n\nRStudio and GitHub\nFor a workflow with RStudio and GitHub on your local computer, you will need four things:\n\nR\nRStudio\nGit\nGitHub\n\nFollow the UCSB MEDS Installation Guide for detailed instructions on how to create accounts, download, install, and configure on Mac and Windows. This takes about 20 minutes. (For an even more detailed walk-through, see Allison Horst’s ESM 206 Google Doc).\n\n\nClone your repo\nYou’ll start by cloning your repository into RStudio.\nFile &gt; New Project &gt; Version Control &gt; Git &gt; paste your repository name.\nR for Excel Users: Clone your repository using RStudio has detailed instructions and screenshots of these steps.\n\n\nInstall Quarto\nNext, you’ll install Quarto: https://quarto.org/docs/get-started/. After downloading, follow the installation wizard on your computer. When it is complete, you won’t see an application or any new software, but it is now available to RStudio (as well as all other applications on your computer, including the command line).\n\n\nRStudio orientation\nNow let’s take a moment to get oriented. This is an RStudio project, which is indicated in the top-right. The bottom right pane shows all the files in your project; everything we’ve cloned from GitHub. We can open any RStudio project by opening its .Rproj file, or from RStudio File &gt; Open Project ….\n\n\n\nRStudio IDE highlighting the project name and files pane\n\n\n\n\nVisual Editor\nThe RStudio Visual Editor is quite new and has features that improve your writing experience. Working in the Visual Editor feels a bit like working in a Google Doc.\nHere’s an example showing the same file in the original Source Editor with content in markdown format and in the Visual Editor with content that looks more like it will appear in a live site. You can switch freely between these modes.\n\n\n\n\n\n\nRStudio IDE highlighting the Source Editor\n\n\n\n\n\n\n\nRStudio IDE highlighting the Visual Editor\n\n\n\n\n\nAlready have some content formatted in a Google Doc? You can copy-paste it into the Visual Editor and most formatting will be retained.\nThe editing bar provides familiar point and click access to text formatting options like bulleted or numbered lists.\n\n\n\nRStudio IDE highlighting the point and click editing bar\n\n\n\nKeyboard shortcuts\nThe Visual Editor also lets you use many keyboard shortcuts that might be familiar for adding boldface (command-b), italics (command-i), or headers. On a Mac, option-command-2 will make a level 2 header. Try it with option-command-1, or option-command-0 for normal text!\n\n\nInsert an image or figure\nTo insert an image (called a figure in Quarto), click the image icon. This brings up a window in which we can select the image, set its alignment, give it a caption and alt text, hyperlink it, or edit other metadata.\n\n\n\nInsert image or figure using the Visual Editor\n\n\nOnce an image is added, clicking on that image gives us editing options. We can resize it dynamically by clicking in the image and dragging a corner or side to resize. When an image is selected, its dimensions are displayed for editing. Clicking on the gray ellipsis to the right of the dimensions opens the pop-up window to access more metadata edits.\n\n\nInsert a table\nSimilar to adding an image, to insert a table, we click the Table dropdown."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#quarto-render",
    "href": "quarto-workflows/rstudio.html#quarto-render",
    "title": "From RStudio",
    "section": "Quarto render",
    "text": "Quarto render\nIn the Build tab in the top-right pane, click “Render Website”. This will build the .html files and preview your website. It’s equivalent to “knitting” in RMarkdown.\nNote that you can also click “Preview Website”. With “Render Website” in RStudio, Quarto is able to render and preview in one step.\nIf you’d ever like to stop the preview, in the bottom-left, click on the Jobs tab and then the red Stop button.\n\nMake a small change and render it\nClick on index.md. This will open this markdown file in a fourth pane; the editor pane. Make a small change, for example change to today’s date on Line 4. Then, save your file; there is a disc icon at the top of the file.\nThen, render this file: press “Render” which is to the right of the disc icon that saves the file. This will render only this single file, as opposed to rerendering the whole website like when we clicked “Render Website” in the top right pane. Checking Render on Save (between the disc icon and the Render button) is a great strategy for doing this in one step."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#create-a-new-.rmd-page",
    "href": "quarto-workflows/rstudio.html#create-a-new-.rmd-page",
    "title": "From RStudio",
    "section": "Create a new .Rmd page",
    "text": "Create a new .Rmd page\nNew &gt; RMarkdown document &gt; OK\nThe starter RMarkdown document has some R code inside: it displays a summary of the cars dataset that is pre-loaded into R (summary(cars)) and plots the pressure data that is also pre-loaded (plot(pressure)).\nSave this document as r-example.rmd."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#update-_quarto.yml",
    "href": "quarto-workflows/rstudio.html#update-_quarto.yml",
    "title": "From RStudio",
    "section": "Update _quarto.yml",
    "text": "Update _quarto.yml\nNow we’ll add r-example.rmd to our _quarto.yml file; this is where we register all files to include in our site. Let’s add it after the section called “Quarto Workflows”.\nOpen _quarto.yml by clicking on it from the file directory.\nScroll down to review the current contents in the sidebar: section under contents:. It’s there we see all the file arrangement that we see in the previewed site.\nAdd - r-example.rmd in its own line, making sure that your indentation aligns with the other pages.\nFrom the Build tab, clicking Preview Website will recreate your website!"
  },
  {
    "objectID": "quarto-workflows/rstudio.html#authoring-tips",
    "href": "quarto-workflows/rstudio.html#authoring-tips",
    "title": "From RStudio",
    "section": "Authoring tips",
    "text": "Authoring tips\nChecking “Render on Save” is really helpful when iterating quickly on a document.\nIf the document is very code-heavy, consider using freeze that will not run the code each time.\nQuarto.org has details about authoring, including specific instructions about authoring in RStudio."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#commit-and-push",
    "href": "quarto-workflows/rstudio.html#commit-and-push",
    "title": "From RStudio",
    "section": "Commit and push!",
    "text": "Commit and push!\nCommitting and pushing will make the changes you see locally live on your website (using the GitHub Action we set up earlier)."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#troubleshooting",
    "href": "quarto-workflows/rstudio.html#troubleshooting",
    "title": "From RStudio",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nIf you have trouble rendering your website after for example changing the extenstion of a file from .md to .qmd, refreshing your RStudio often helps. Do this by clicking the project name at the upper right of the RStudio window (in this case, quarto-website-tutorial), and underneath the “close project” section, click the same name of your project: quarto-website-tutorial. This will relaunch your whole project afresh."
  },
  {
    "objectID": "irb/ModelGuideline.html",
    "href": "irb/ModelGuideline.html",
    "title": "Model guideline",
    "section": "",
    "text": "Nhìn tổng thể chân dung khách hàng"
  },
  {
    "objectID": "irb/ModelGuideline.html#triết-lý-xây-dựng-mô-hình",
    "href": "irb/ModelGuideline.html#triết-lý-xây-dựng-mô-hình",
    "title": "Model guideline",
    "section": "",
    "text": "Nhìn tổng thể chân dung khách hàng"
  },
  {
    "objectID": "irb/ModelGuideline.html#phạm-vi-mô-hình",
    "href": "irb/ModelGuideline.html#phạm-vi-mô-hình",
    "title": "Model guideline",
    "section": "Phạm vi mô hình",
    "text": "Phạm vi mô hình\n\nCần xác định rõ phạm vi của mô hình trước khi bắt đầu xây dựng & phát triển mô hình"
  },
  {
    "objectID": "irb/ModelGuideline.html#single-factor-analysis",
    "href": "irb/ModelGuideline.html#single-factor-analysis",
    "title": "Model guideline",
    "section": "Single factor analysis",
    "text": "Single factor analysis\n\nWoE binning\n\nSố lượng nhóm phân chia dựa trên tỷ lệ bad rate tương đối, nếu 5 nhóm thì nhóm thứ 3 tỷ lệ này xấp xỉ 1\nSố lượng nhóm khoảng 5-7 nhóm (đẹp nhất là 5 nhóm)\nNên chọn số lượng nhóm số lẻ\nMissing tùy thuộc từng trường hợp sẽ nhóm vào nhóm có tỷ lệ bad rate cao nhất hoặc nhóm có tỷ lệ bad rate xấp xỉ\nTùy từng biến có trend sẽ coasre trend theo biến\n\n\n\nChuẩn hóa biến\n\nNormalising Score: Dùng để dễ so sánh coef của mô hình đa biến sau khi đã hồi quy. Normalised Log Odds thông thường có trung bình = 0, std = 50"
  },
  {
    "objectID": "irb/ModelGuideline.html#multiple-factors-analysis",
    "href": "irb/ModelGuideline.html#multiple-factors-analysis",
    "title": "Model guideline",
    "section": "Multiple Factors Analysis",
    "text": "Multiple Factors Analysis\n\nTheo triết lý xây dựng mô hình, mỗi nhóm thông tin khách hàng có ít nhất 1 biến:\nVD: Nhóm thông tin chung có 1 biến, nhóm thông tin hành vi tiêu dùng 3 biến, … các nhóm thông tin còn lại có ít nhất 1 biến"
  },
  {
    "objectID": "irb/ModelGuideline.html#chọn-mô-hình-cuối-cùng",
    "href": "irb/ModelGuideline.html#chọn-mô-hình-cuối-cùng",
    "title": "Model guideline",
    "section": "Chọn mô hình cuối cùng",
    "text": "Chọn mô hình cuối cùng\n\n30% &gt; std-coef &gt; 5%\nNếu có hệ số dưới 5%, điều chỉnh lại trọng số = 5%, rồi nhân ngược lại ra adjusted-coef\nCân nhắc trọng số của các nhóm thông tin: Ví dụ: Nhóm thông tin A có 2 biến tổng trọng số 10%, nhóm thông tin B có 3 biến tổng trọng số 50% (nhóm thông tin B này quá mạnh so với nhóm thông tin A)\nNên tăng hoặc giảm hệ số các biến trong cùng 1 nhóm thông tin"
  },
  {
    "objectID": "irb/ModelGuideline.html#kiểm-định-mô-hình",
    "href": "irb/ModelGuideline.html#kiểm-định-mô-hình",
    "title": "Model guideline",
    "section": "Kiểm định mô hình",
    "text": "Kiểm định mô hình"
  },
  {
    "objectID": "irb/ModelGuideline.html#giám-sát-mô-hình",
    "href": "irb/ModelGuideline.html#giám-sát-mô-hình",
    "title": "Model guideline",
    "section": "Giám sát mô hình",
    "text": "Giám sát mô hình\n\nGini đơn biến suy giảm quá 15%, hoặc 10% cho các biến nhân khẩu học điều chỉnh lại mô hình\nSau khi mô hình vi phạm các ngưỡng thì xem xét lại mô hình\nBáo cáo lại những yếu tố ảnh hưởng tới mô hình. VD: Tình hình cho vay, …\nFront-end monitoring: Xem sự dịch chuyển các nhóm hạng, danh mục\nBack-end monitoring: performance (test trên cả overall, sub-segment)của mô hình vẫn tốt, các factors vẫn phản ánh được kết quả của mô hình. Tùy thuộc dữ liệu có thể ấy dữ liệu từ 2 năm đến 5 năm dữ liệu\nThông thường các factors dễ thay đổi, có thể chạy mô hình trên dữ liệu mới\nPopulation thay đổi (PSI):\n\nFront-end\n\n\n\n\n\n\n\n\n\n\n\nDev\nOOT\nRemark\n\n\n\n\nPSI\nNA\n3.1%\nChỉ số ổn định tổng thể (PSI)\n- PSI &lt; 15%: chỉ số phân phối điểm ổn định.\n- PSI &gt;= 15% và &lt; 25%: chỉ số dịch chuyển vừa phải.\n- PSI &gt;=25%: thể hiện sự thay đổi đáng kể.\nNếu có sự thay đổi đáng kể, thẻ điểm có thể không áp dụng cho mẫu OOT.\n\n\n\nAHI\n5.1%\n4.0%\nChỉ số Herfindah được điều chỉnh (AHI) để đo độ tập trung trong dải điểm nhất định.\n- AHI &lt; 20%: không tập trung\n- AHI &gt;= 20%: có sự tập trung trong dải điểm nhất định. Cần điều tra để đảm bảo không có vấn đề gì với khả năng phân biệt rủi ro.\n\n\n\nBack-end\n\n\n\n\n\n\n\n\nOverall\nDev\nOOT\n\n\n\n\nGini\n\n\n\n\nNo of default\n\n\n\n\nOutcome\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSub-segment\nRisk Ranking\n\nDefault\n\nOutcome\n\n\n\n\n\n\nDev\nOOT\nDev\nOOT\nBaseline\n2020\n\n\nProduct type\n\n\n\n\n\n\n\n\nCredit card only\n\n\n\n\n\n\n\n\nPersonal Loan only\n\n\n\n\n\n\n\n\nĐơn vị kinh doanh\n\n\n\n\n\n\n\n\nHO\n\n\n\n\n\n\n\n\nCông ty tài chính\n\n\n\n\n\n\n\n\n\nFactor mới thêm vào có thể dùng phương pháp điều chỉnh weight"
  },
  {
    "objectID": "irb/ModelGuideline.html#chuyển-đổi-điểm",
    "href": "irb/ModelGuideline.html#chuyển-đổi-điểm",
    "title": "Model guideline",
    "section": "Chuyển đổi điểm",
    "text": "Chuyển đổi điểm"
  },
  {
    "objectID": "irb/ModelGuideline.html#apply-irb",
    "href": "irb/ModelGuideline.html#apply-irb",
    "title": "Model guideline",
    "section": "Apply IRB",
    "text": "Apply IRB\n\nQuy trình tín dụng\nQuy trình đánh giá khách hàng"
  },
  {
    "objectID": "irb/ModelGuideline.html#pd-model-calibration",
    "href": "irb/ModelGuideline.html#pd-model-calibration",
    "title": "Model guideline",
    "section": "PD Model Calibration",
    "text": "PD Model Calibration\n\nHousing loan: với 6 tháng hành vi trả nợ chưa đủ mạnh, chưa có nhiều behavious, sử dụng MoB 12 để xác định khách hàng mới hoặc cũ\nThẻ tín dụng: chỉ cần 6 tháng đã có được hành vi tiêu dùng, trả nợ\nChú ý tính đồng nhất của danh mục\nNếu thay đổi chính sách thì mô hình phải phản ánh chính sách forward-looking\nNếu không có thông tin liên quan đến thị trường, thì phải có điều chỉnh downgrade PD\nA-score: Cyclicality ~ 40 -50%, B-score ~ 60-70%\nƯớc tính cyclicality: do 1 model thường không dùng qua 1 chu kỳ kinh tế, nếu back score thì có thẻ dữ liệu cũ không đủ. Những biến như age, gender thì không có cyclicality\nRetail có thể có master scale riêng với từng danh mục, nhưng có thể distribution không đẹp"
  },
  {
    "objectID": "irb/ModelGuideline.html#xác-định-chu-kỳ-kinh-tế",
    "href": "irb/ModelGuideline.html#xác-định-chu-kỳ-kinh-tế",
    "title": "Model guideline",
    "section": "Xác định chu kỳ kinh tế",
    "text": "Xác định chu kỳ kinh tế\n\nThu thập dữ liệu càng dài càng tốt, tối thiểu 5 năm\nThị trường châu á, lấy mốc khủng hoảng kinh tế là 1998\nDùng portfolio có tính chất tương tự, có thể dùng portfolio tương tự của Central Bank NPL, chứng minh correlation sau đó extrapolate\nForward looking, chọn số trung bình giữa baseline và worst-case\nTrong giai đoạn covid, nếu có nhà nước có nhiều chính sách làm cho odr giảm, thì có thể bỏ những data point này ra khỏi mẫu trong thời kỳ crisis"
  },
  {
    "objectID": "irb/ModelGuideline.html#chia-pool",
    "href": "irb/ModelGuideline.html#chia-pool",
    "title": "Model guideline",
    "section": "Chia pool",
    "text": "Chia pool\n\nDựa trên product types, pd, mob, bucket …"
  },
  {
    "objectID": "irb/ModelGuideline.html#đánh-giá-lại-pd",
    "href": "irb/ModelGuideline.html#đánh-giá-lại-pd",
    "title": "Model guideline",
    "section": "Đánh giá lại PD",
    "text": "Đánh giá lại PD\n\ndựa vào CT, ODR, đánh giá implied pd còn phù hợp hay không"
  },
  {
    "objectID": "irb/ModelGuideline.html#moc",
    "href": "irb/ModelGuideline.html#moc",
    "title": "Model guideline",
    "section": "MoC",
    "text": "MoC"
  },
  {
    "objectID": "irb/ModelGuideline.html#thấu-chi",
    "href": "irb/ModelGuideline.html#thấu-chi",
    "title": "Model guideline",
    "section": "Thấu chi",
    "text": "Thấu chi\n\nCó tài sản đảm bảo\n\nNếu là KH housing loan vay thêm thấu chi, có thể dùng housing score card\n\n\n\nNếu tài sản là tiền gửi nhỏ, thì áp dụng standardise\n\nKhông có tài sản\n\nXếp chung vào nhóm credit card"
  },
  {
    "objectID": "models-monitoring/KS-PSI_ENTROPY.html",
    "href": "models-monitoring/KS-PSI_ENTROPY.html",
    "title": "Giám sát độ ổn định của mô hình",
    "section": "",
    "text": "Chỉ số Ổn định tổng thể (PSI - Population Stability Index) là một phép đo thường được sử dụng trong ngành ngân hàng, đặc biệt trong việc xếp hạng tín dụng, để giám sát sự ổn định và hiệu suất của các mô hình xếp hạng theo thời gian. Đây là cách để định lượng sự thay đổi trong phân phối tổng thể, điều này có thể ảnh hưởng đến sức mạnh dự đoán của một mô hình.\n\nPSI được tính như sau:\n\\[ PSI = \\sum_{i=1}^{N} (Actual_{i} - Expected_{i}) \\log \\left( \\frac{Actual_{i}}{Expected_{i}} \\right) \\]\nTrong đó:\n\n\\(Actual_{i}\\) và \\(Expected_{i}\\) là tỷ lệ quan sát rơi vào bin (i) cho dữ liệu thực tế (mới hoặc kiểm tra) và dữ liệu mong đợi (cũ hoặc đào tạo), tương ứng. - (N) là tổng số bins.\n\nCách giải thích thông thường về các giá trị PSI như sau:\n\nPSI &lt; 0.1: Không có sự thay đổi đáng kể về tổng thể. Mô hình thường được coi là ổn định.\n0.1 ≤ PSI &lt; 0.25: Có một số thay đổi nhỏ trong tổng thể, có thể cần được điều tra thêm.\nPSI ≥ 0.25: Sự thay đổi đáng kể về tổng thể. Mô hình có thể không còn phù hợp và cần được cập nhật hoặc xây dựng lại.\n\nLưu ý rằng những ngưỡng này không phải là cố định và có thể thay đổi tùy thuộc vào đặc điểm cụ thể của tình huống và mức độ rủi ro bạn sẵn sàng chấp nhận.\n\nimport numpy as np\ndef calculate_psi(expected, actual, bins=10, categorical=False):\n    \"\"\"\n    Calculate the PSI (Population Stability Index) between expected and actual data.\n    \n    Args:\n    expected: numpy array of original values\n    actual: numpy array of new values, same size as expected\n    bins: number of bins to use in calculation, defaults to 10\n    categorical: boolean, if True indicates that the input variables are categorical\n    \n    # Example usage for categorical variables:\n    expected_categorical = np.random.choice(['A', 'B', 'C'], size=500, p=[0.4, 0.5, 0.1])\n    actual_categorical = np.random.choice(['A', 'B', 'C'], size=500, p=[0.42, 0.48, 0.1]) \n    \n    psi_value_categorical = calculate_psi(expected_categorical, actual_categorical, categorical=True)\n    psi_value_categorical\n    \n    Returns:\n    psi_value: calculated PSI value\n    \"\"\"\n\n    # Check if the variables are categorical\n    if categorical:\n        # Get unique categories\n        categories = np.unique(np.concatenate([expected, actual]))\n        \n        # Calculate the expected and actual proportions for each category\n        expected_probs = np.array([np.sum(expected == cat) for cat in categories]) / len(expected)\n        actual_probs = np.array([np.sum(actual == cat) for cat in categories]) / len(actual)\n    else:\n        # Define the bin edges for the histogram\n        bin_edges = np.histogram_bin_edges(expected, bins=bins)\n\n        # Calculate the expected and actual proportions for each bin\n        expected_probs, _ = np.histogram(expected, bins=bin_edges)\n        actual_probs, _ = np.histogram(actual, bins=bin_edges)\n\n        # Normalize to get proportions\n        expected_probs = expected_probs / len(expected)\n        actual_probs = actual_probs / len(actual)\n\n    # Initialize PSI\n    psi_value = 0\n\n    # Loop over each bin or category\n    for bin in range(len(expected_probs)):\n        # Avoid division by zero and log of zero\n        if expected_probs[bin] == 0 or actual_probs[bin] == 0:\n            continue\n        # Calculate the PSI for this bin or category\n        psi_value += (expected_probs[bin] - actual_probs[bin]) * np.log(expected_probs[bin] / actual_probs[bin])\n\n    return psi_value"
  },
  {
    "objectID": "models-monitoring/KS-PSI_ENTROPY.html#psi",
    "href": "models-monitoring/KS-PSI_ENTROPY.html#psi",
    "title": "Giám sát độ ổn định của mô hình",
    "section": "",
    "text": "Chỉ số Ổn định tổng thể (PSI - Population Stability Index) là một phép đo thường được sử dụng trong ngành ngân hàng, đặc biệt trong việc xếp hạng tín dụng, để giám sát sự ổn định và hiệu suất của các mô hình xếp hạng theo thời gian. Đây là cách để định lượng sự thay đổi trong phân phối tổng thể, điều này có thể ảnh hưởng đến sức mạnh dự đoán của một mô hình.\n\nPSI được tính như sau:\n\\[ PSI = \\sum_{i=1}^{N} (Actual_{i} - Expected_{i}) \\log \\left( \\frac{Actual_{i}}{Expected_{i}} \\right) \\]\nTrong đó:\n\n\\(Actual_{i}\\) và \\(Expected_{i}\\) là tỷ lệ quan sát rơi vào bin (i) cho dữ liệu thực tế (mới hoặc kiểm tra) và dữ liệu mong đợi (cũ hoặc đào tạo), tương ứng. - (N) là tổng số bins.\n\nCách giải thích thông thường về các giá trị PSI như sau:\n\nPSI &lt; 0.1: Không có sự thay đổi đáng kể về tổng thể. Mô hình thường được coi là ổn định.\n0.1 ≤ PSI &lt; 0.25: Có một số thay đổi nhỏ trong tổng thể, có thể cần được điều tra thêm.\nPSI ≥ 0.25: Sự thay đổi đáng kể về tổng thể. Mô hình có thể không còn phù hợp và cần được cập nhật hoặc xây dựng lại.\n\nLưu ý rằng những ngưỡng này không phải là cố định và có thể thay đổi tùy thuộc vào đặc điểm cụ thể của tình huống và mức độ rủi ro bạn sẵn sàng chấp nhận.\n\nimport numpy as np\ndef calculate_psi(expected, actual, bins=10, categorical=False):\n    \"\"\"\n    Calculate the PSI (Population Stability Index) between expected and actual data.\n    \n    Args:\n    expected: numpy array of original values\n    actual: numpy array of new values, same size as expected\n    bins: number of bins to use in calculation, defaults to 10\n    categorical: boolean, if True indicates that the input variables are categorical\n    \n    # Example usage for categorical variables:\n    expected_categorical = np.random.choice(['A', 'B', 'C'], size=500, p=[0.4, 0.5, 0.1])\n    actual_categorical = np.random.choice(['A', 'B', 'C'], size=500, p=[0.42, 0.48, 0.1]) \n    \n    psi_value_categorical = calculate_psi(expected_categorical, actual_categorical, categorical=True)\n    psi_value_categorical\n    \n    Returns:\n    psi_value: calculated PSI value\n    \"\"\"\n\n    # Check if the variables are categorical\n    if categorical:\n        # Get unique categories\n        categories = np.unique(np.concatenate([expected, actual]))\n        \n        # Calculate the expected and actual proportions for each category\n        expected_probs = np.array([np.sum(expected == cat) for cat in categories]) / len(expected)\n        actual_probs = np.array([np.sum(actual == cat) for cat in categories]) / len(actual)\n    else:\n        # Define the bin edges for the histogram\n        bin_edges = np.histogram_bin_edges(expected, bins=bins)\n\n        # Calculate the expected and actual proportions for each bin\n        expected_probs, _ = np.histogram(expected, bins=bin_edges)\n        actual_probs, _ = np.histogram(actual, bins=bin_edges)\n\n        # Normalize to get proportions\n        expected_probs = expected_probs / len(expected)\n        actual_probs = actual_probs / len(actual)\n\n    # Initialize PSI\n    psi_value = 0\n\n    # Loop over each bin or category\n    for bin in range(len(expected_probs)):\n        # Avoid division by zero and log of zero\n        if expected_probs[bin] == 0 or actual_probs[bin] == 0:\n            continue\n        # Calculate the PSI for this bin or category\n        psi_value += (expected_probs[bin] - actual_probs[bin]) * np.log(expected_probs[bin] / actual_probs[bin])\n\n    return psi_value"
  },
  {
    "objectID": "models-monitoring/KS-PSI_ENTROPY.html#ks-kolmogorov-smirnov",
    "href": "models-monitoring/KS-PSI_ENTROPY.html#ks-kolmogorov-smirnov",
    "title": "Giám sát độ ổn định của mô hình",
    "section": "KS (Kolmogorov-Smirnov)",
    "text": "KS (Kolmogorov-Smirnov)\n\nKiểm định KS (Kolmogorov-Smirnov) là một kiểm định thống kê phi tham số dùng để so sánh hai phân phối tích lũy (CDFs) hoặc một mẫu dữ liệu với một phân phối lý thuyết. Nó có hai ứng dụng chính:\n\nKiểm tra sự phù hợp của mẫu: Được sử dụng để kiểm tra xem một tập dữ liệu có tuân theo một phân phối lý thuyết cụ thể (như phân phối chuẩn, phân phối đều, v.v.) hay không.\nSo sánh hai mẫu dữ liệu: Được sử dụng để kiểm tra xem hai tập dữ liệu có xuất phát từ cùng một phân phối gốc hay không.\n\nCông thức tính toán cho chỉ số KS là:\n\\[ D = \\max |F_1(x) - F_2(x)| \\]\nTrong đó:\n\n$ F_1(x) $ và $F_2(x) $ là hai hàm phân phối tích lũy cần so sánh.\nD là giá trị lớn nhất của sự khác biệt tuyệt đối giữa hai hàm phân phối tích lũy trên toàn bộ phạm vi x.\n\nMột đặc điểm quan trọng của kiểm định KS là nó không yêu cầu giả định về dạng của phân phối, làm cho nó trở thành một công cụ mạnh mẽ và linh hoạt khi so sánh phân phối.\n\nfrom scipy.stats import ks_2samp\n\n# Generate two sample datasets\ndata1 = np.random.normal(0, 1, 1000)\ndata2 = np.random.normal(0.5, 1.5, 1000)\n\n# Compute the KS statistic and p-value\nks_statistic, p_value = ks_2samp(data1, data2)\n\nks_statistic, p_value\n\n(0.208, 2.4178548709800775e-19)"
  },
  {
    "objectID": "models-monitoring/KS-PSI_ENTROPY.html#divergence-test-cross-entropy",
    "href": "models-monitoring/KS-PSI_ENTROPY.html#divergence-test-cross-entropy",
    "title": "Giám sát độ ổn định của mô hình",
    "section": "Divergence Test (cross-entropy)",
    "text": "Divergence Test (cross-entropy)\n\nKiểm định Divergence, thường được gọi là Divergence Kullback-Leibler (KL), là một chỉ số đo sự khác biệt giữa một phân phối xác suất so với một phân phối xác suất thứ hai mong đợi. Nó được sử dụng để so sánh hai phân phối xác suất cho cùng một sự kiện.\nCho hai phân phối xác suất, P và Q, Divergence Kullback-Leibler của Q so với P được định nghĩa như sau:\n\\[ D_{KL}(P||Q) = \\sum_{i} P(i) \\log \\left( \\frac{P(i)}{Q(i)} \\right)\\]\nTrong đó:\n\n\\(P(i)\\) là xác suất của sự kiện i theo phân phối P,\n\\(Q(i)\\) là xác suất của sự kiện i theo phân phối Q,\nTổng được tính trên tất cả các sự kiện i có thể xảy ra.\n\nMột số điểm quan trọng về KL Divergence:\n\nKhông đối xứng: \\(D_{KL}(P||Q)\\) không bằng \\(D_{KL}(Q||P)\\). Điều này có nghĩa là Divergence KL của Q so với P không giống như Divergence KL của P so với Q.\nKhông âm: Divergence KL luôn không âm, và nó bằng không chỉ khi P và Q là cùng một phân phối.\nĐơn vị: Divergence KL được đo bằng bit nếu logarithm có cơ số 2 (log2), hoặc bằng nats nếu logarithm có cơ số e (logarithm tự nhiên).\n\nTrên thực tế, KL Divergence có thể được sử dụng để đo sự khác biệt giữa phân phối thực tế và dự đoán, hoặc giữa một phân phối quan sát và một phân phối lý thuyết. Nó đặc biệt phổ biến trong các lĩnh vực như lý thuyết thông tin và học máy.\n\nimport numpy as np\n\ndef kl_divergence(p, q):\n    \"\"\"Compute KL divergence of two probability distributions.\"\"\"\n    return np.sum(p * np.log(p / q))\n\n# Example distributions\np = np.array([0.4, 0.5, 0.1])\nq = np.array([0.3, 0.4, 0.3])\n\n# Ensure the distributions are valid (i.e., sum to 1 and non-negative)\nassert np.all(p &gt;= 0) and np.all(q &gt;= 0)\nassert np.isclose(p.sum(), 1) and np.isclose(q.sum(), 1)\n\n# Calculate KL Divergence\ndivergence_value = kl_divergence(p, q)\nprint(f\"KL Divergence between p and q: {divergence_value:.4f}\")\n\nKL Divergence between p and q: 0.1168\n\n\n\nimport numpy as np\nfrom scipy.stats import entropy\n\ndef kl_divergence(p, q):\n    \"\"\"Compute KL divergence of two probability distributions.\"\"\"\n    return entropy(p, q)\n\n# Example distributions\np = np.array([0.4, 0.5, 0.1])\nq = np.array([0.3, 0.4, 0.3])\n\n# Calculate KL Divergence from p to q\ndivergence_value = kl_divergence(p, q)\n\nprint(f\"Cross entropy: {divergence_value:.4f}\")\n\nCross entropy: 0.1168"
  },
  {
    "objectID": "models-monitoring/KS-PSI_ENTROPY.html#so-sánh-ks-và-divergence",
    "href": "models-monitoring/KS-PSI_ENTROPY.html#so-sánh-ks-và-divergence",
    "title": "Giám sát độ ổn định của mô hình",
    "section": "So sánh KS và Divergence",
    "text": "So sánh KS và Divergence\n\nMục đích:\n\nKiểm định KS: Đây là một kiểm định phi tham số được sử dụng để xác định xem hai mẫu có xuất phát từ cùng một phân phối hay không. Thống kê KS đo sự khác biệt lớn nhất giữa các hàm phân phối tích lũy (CDFs) của hai mẫu.\nKiểm định Divergence (KL Divergence): Nó đo cách một phân phối xác suất khác biệt so với một phân phối xác suất thứ hai mong đợi. Nó thường được sử dụng trong lý thuyết thông tin để đo “khoảng cách” giữa hai phân phối.\n\nKết quả:\n\nKiểm định KS: Kết quả là một chỉ số (D) đại diện cho sự khác biệt lớn nhất giữa hai CDFs và một giá trị p kiểm tra giả thuyết rằng hai mẫu được rút ra từ cùng một phân phối.\nKiểm định Divergence (KL Divergence): Kết quả là một giá trị không âm, trong đó giá trị 0 chỉ ra rằng hai phân phối là giống nhau. Lưu ý rằng KL Divergence không đối xứng, tức là \\(D_{KL}(P||Q) \\neq D_{KL}(Q||P)\\).\n\nGiả định:\n\nKiểm định KS: Không giả định về phân phối của dữ liệu.\nKiểm định Divergence (KL Divergence): Giả định \\(Q(i) &gt; 0\\) cho bất kỳ i nào sao cho \\(P(i) &gt; 0\\), nếu không sự khác biệt sẽ vô cùng.\n\nỨng dụng:\n\nKiểm định KS: Thường được sử dụng trong kiểm định giả thuyết để xác định xem một mẫu dữ liệu có tuân theo một phân phối cụ thể hay không.\nKiểm định Divergence (KL Divergence): Rộng rãi được sử dụng trong lý thuyết thông tin, học máy và thống kê, đặc biệt khi so sánh một phân phối thực nghiệm với một phân phối lý thuyết.\n\nGiải thích:\n\nKiểm định KS: Một giá trị p nhỏ cho thấy rằng hai mẫu đến từ các phân phối khác nhau.\nKiểm định Divergence (KL Divergence): Một Divergence KL lớn hơn chỉ ra rằng hai phân phối khác biệt hơn so với nhau.\n\n\nTóm lại, mặc dù cả Kiểm định KS và KL Divergence đều được sử dụng để so sánh các phân phối, nhưng chúng có các phương pháp, giải thích và ứng dụng khác nhau. Sự lựa chọn giữa chúng phụ thuộc vào vấn đề cụ thể và bản chất của dữ liệu."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Making shareable documents with Quarto",
    "section": "",
    "text": "It’s possible to create beautiful documentation to share online with Quarto that auto-updates with GitHub. This is very new and incredibly cool. This tutorial is an example of a quarto website — it is a really powerful way to create and share your work. You can communicate about science using the same reproducible workflow you and/or your colleagues use for analyses, whether or not you write code.\nCreating websites with Quarto can be done without knowing R, Python or HTML, CSS, etc, and that’s where we’ll start. However, Quarto integrates with these tools so you can make your websites as complex and beautiful as you like as you see examples and reuse and remix from others in the open community. This tutorial borrows heavily from a lot of great tutorials and resources you should check out too – there are links throughout."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Making shareable documents with Quarto",
    "section": "",
    "text": "It’s possible to create beautiful documentation to share online with Quarto that auto-updates with GitHub. This is very new and incredibly cool. This tutorial is an example of a quarto website — it is a really powerful way to create and share your work. You can communicate about science using the same reproducible workflow you and/or your colleagues use for analyses, whether or not you write code.\nCreating websites with Quarto can be done without knowing R, Python or HTML, CSS, etc, and that’s where we’ll start. However, Quarto integrates with these tools so you can make your websites as complex and beautiful as you like as you see examples and reuse and remix from others in the open community. This tutorial borrows heavily from a lot of great tutorials and resources you should check out too – there are links throughout."
  },
  {
    "objectID": "index.html#what-is-quarto",
    "href": "index.html#what-is-quarto",
    "title": "Making shareable documents with Quarto",
    "section": "What is Quarto?",
    "text": "What is Quarto?\nQuarto helps you have your ideas and your code in one place, and present it in a beautiful way.\nQuarto unifies and extends the RMarkdown ecosystem - it unifies by combining the functionality of R Markdown, bookdown, distill, xaringian, etc into a single consistent system. And it extends in several ways: all features are possible beyond R too, including Python and Javascript. It also has more “guardrails”: accessibility and inclusion are centered in the design. Quarto is for people who love RMarkdown, and it’s for people who have never used RMarkdown.\nThe ability for Quarto to streamline collaboration has been so cool and important for our NASA Openscapes project. Quarto has been a common place for us to collaborate - across R and Python languages and coding expertise."
  },
  {
    "objectID": "index.html#what-is-this-tutorial",
    "href": "index.html#what-is-this-tutorial",
    "title": "Making shareable documents with Quarto",
    "section": "What is this tutorial?",
    "text": "What is this tutorial?\nThis is a 1-hour tutorial that can be used to teach or as self-paced learning.\nWe introduce Quarto by exploring this tutorial website, and practicing the basic Quarto workflow using different tools (GitHub browser, RStudio, and Jupyter) for editing your website.\nWe’ll start off from the browser so you don’t need to install any additional software, however this approach is very limited and you will soon outgrow its capabilities. If you don’t already have a workflow to edit files and sync to GitHub from your computer, I recommend RStudio. You don’t need to know R to use RStudio, and it has powerful editor features that make for happy workflows.\nQuarto.org is the go-to place for full documentation and more tutorials!"
  },
  {
    "objectID": "index.html#example-quarto-sites",
    "href": "index.html#example-quarto-sites",
    "title": "Making shareable documents with Quarto",
    "section": "Example Quarto sites",
    "text": "Example Quarto sites\nA few Quarto websites from Openscapes - so far we have been using Quarto for documentation using Quarto and Markdown files and Jupyter Notebooks.\n\nChampions Lessons Series\nOpenscapes Approach Guide\n\n2021 NASA Cloud Hackathon\nFaylab Lab Manual\nA Quarto tip a day, by Mine Çetinkaya-Rundel"
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Making shareable documents with Quarto",
    "section": "About",
    "text": "About\nOpenscapes is about better science for future us. We help researchers reimagine data analysis, develop modern skills that are of immediate value to them, and cultivate collaborative and inclusive research teams as part of the broader global open movement.\nWe’re developing this tutorial to help folks with different levels of technical skills use Quarto for documentation and tutorial building. This tutorial was originally created for several different audiences: NASA-Openscapes researcher support engineers using Python, communications directors at organizations promoting open science who do not identify as coders, and fisheries scientists curious about transitioning from RMarkdown. We’re hoping it’s useful to folks with backgrounds as wide as these; if you find it useful or have suggestions for improvement, please let us know by clicking “Edit this page” or “Report an issue” at the upper right side of any page."
  },
  {
    "objectID": "learning-more.html",
    "href": "learning-more.html",
    "title": "Learning more",
    "section": "",
    "text": "An excellent overview: Reproducible authoring with Quarto - Mine Çetinkaya-Rundel, Feb 2022 - slides, youtube\nA Quarto tip a day in June 2022, from Mine Çetinkaya-Rundel.\n\n\n\nOpenscapes Champions Lessons Series\nOpenscapes Approach Guide\n\nNASA Earthdata Cloud Cookbook\n\nSee many more examples at the quarto gallery!\n\n\n\nAre you making onboarding documentation? Check out The Fay Lab Manual (now in Quarto!) for inspiration on structure - you could also start there and make it your own."
  },
  {
    "objectID": "learning-more.html#learn-more",
    "href": "learning-more.html#learn-more",
    "title": "Learning more",
    "section": "",
    "text": "An excellent overview: Reproducible authoring with Quarto - Mine Çetinkaya-Rundel, Feb 2022 - slides, youtube\nA Quarto tip a day in June 2022, from Mine Çetinkaya-Rundel.\n\n\n\nOpenscapes Champions Lessons Series\nOpenscapes Approach Guide\n\nNASA Earthdata Cloud Cookbook\n\nSee many more examples at the quarto gallery!\n\n\n\nAre you making onboarding documentation? Check out The Fay Lab Manual (now in Quarto!) for inspiration on structure - you could also start there and make it your own."
  },
  {
    "objectID": "transition-from-rmarkdown.html",
    "href": "transition-from-rmarkdown.html",
    "title": "Transition from RMarkdown",
    "section": "",
    "text": "You may already have workflows in RMarkdown and are interested in transitioning to Quarto. There’s no hurry to migrate to Quarto. Keep using Rmarkdown and when you’re ready the migration will be fine.\nHere are some notes as we migrate RMarkdown sites and books.\nTODO: translating R code chunks"
  },
  {
    "objectID": "transition-from-rmarkdown.html#bookdown-to-quarto",
    "href": "transition-from-rmarkdown.html#bookdown-to-quarto",
    "title": "Transition from RMarkdown",
    "section": "Bookdown to Quarto",
    "text": "Bookdown to Quarto\nConverting a Bookdown book to Quarto is slightly more involved than converting a website. A book has chapters whose order must be defined, and likely has citations and cross-refs. Still, conversion is not that hard.\nWe got some practice converting from Bookdown to Quarto by helping Gavin Fay convert his lab’s fantastic onboarding documentation, the Faylab Lab Manual. Here’s the GitHub view before and after.\nOur best first reference material for this was Nick Tierney’s Notes on Changing from Rmarkdown/Bookdown to Quarto. Nick shares some scripts in that post to automate some changes. In our case, the book was small enough that we made all changes manually. Quarto documentation was indispensable.\n\nExperimenting in a low-risk environment\nWe forked a copy of the Faylab Lab manual to the Openscapes organization, and worked in a branch so we could make changes relatively risk-free. We could always fork a new copy of the original if we “broke” something. (Caution: the default when making a pull request from a fork is to push changes to the original upstream repo, not your fork and it does this without warning if you have write-access to that repo.) With local previews it’s easy to test / play with settings to see what they do. We tended to make a change, Preview, then compare the look and functionality of the book to the original. It was helpful to comment out some elements of the configuration file _output.yml after their counterparts had been added to the Quarto configuration file _quarto.yml, or to confirm they were no longer needed, before making the drastic move of deleting them.\n\n\nThe conversion\nHere are the main steps to convert the Faylab Lab manual from Bookdown to Quarto.\nCreate new empty file called _quarto.yml and add book metadata there. The screenshots below\nSet project type as book.\nMove metadata out of index.qmd and into _quarto.yml. Title, author, and publication date were in index.qmd with date set using date: \"Last updated:r Sys.Date()\". Now these are in _quarto.yml with date set using date: last-modified. Note that having R code would require you to adjust code chunk options in the Quarto style (#|). This tripped us up a bit; see GitHub Actions.\nMove chapters listing out of _bookdown.yml and into _quarto.yml.\nAdd page footer to _quarto.yml.\nHere’s what ours looked like when we finished the steps above (_quarto.yml).\n\n\n\n\n\n\n_quarto.yml contents\n\n\n\n\n\n\n\nFaylab Lab Manual\n\n\n\n\n\nChange insertion of images from html style to Quarto style. (Note Quarto calls them “figures”, not “images”.) The following snippet will insert the GitHub octocat logo in a page:\n![](https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png){fig-align=\"left\" width=\"35px\"}\nChange all filename extensions .Rmd -&gt; .qmd (you could Preview after this change and see that the book looks the same). Note that Quarto works with .Rmd files just as well as it does .qmd, so this change is not urgent. In fact, if you have a lot of R code in your .Rmds (unlike the Faylab Lab Manual), there will be additional tinkering needed to make the code chunks happy.\n\n\nCitations\nThe Faylab Lab Manual cited two papers, presenting us with an opportunity to see how easy it is to add references to a Quarto book. Briefly, in the Visual Editor, Insert &gt; Citation &gt; DOI. Pasting the DOI or its full URL, we can insert the citation. This automatically creates a references.bib file and adds the full citations at the bottom of the chapter page (watch demo). In July 2022, we had to manually add a ## References heading, but this may not be necessary in future Quarto updates.\n\n\n\n\n\n\nInsert citation via its DOI using RStudio Visual Editor\n\n\n\n\n\n\n\n\n\n\nPublishing notes\nIf the book’s output is strictly html, there’s no need to specify output-dir in _quarto.yml. The output directory default is _book/, which is what we’d like. If we wanted other types of output like like PDF or EPUB, etc. those single file outputs are also written to the output-dir (Quarto docs).\nIf you currently have a docs/ folder, delete it.\nUpdate .gitignore to ignore _book/. At the same time, we have it ignore caches and a .quarto file:\n/.quarto/\n*_cache/\n_book/\nOnce all is settled, delete _output.yml.\nOnce the Openscapes fork was fully reviewed, we made a pull request from that to the main branch of the book’s repo. Once that was merged, we set up GitHub Actions to render the book. (TODO: instructions for GitHub Actions)\n\n\nGitHub Actions\nThis book was mostly prose and screenshots without any R code. This made the conversion from RMarkdown to Quarto likely more straightforward than if you also needed to adjust code chunk options in the quarto style (#|). Our initial GitHub Action to render the converted Faylab Lab Manual failed because we had a piece of R code - even though the code was commented out! This was resolved when we deleted the line."
  },
  {
    "objectID": "transition-from-rmarkdown.html#distill-to-quarto",
    "href": "transition-from-rmarkdown.html#distill-to-quarto",
    "title": "Transition from RMarkdown",
    "section": "Distill to quarto",
    "text": "Distill to quarto\nWe transitioned our events site from distill to quarto in May 2022 (github view before and after). We followed excellent notes and examples from Nick Tierney and Danielle Navarro.\nAfter we had changed all the files, the Build tab in the RStudio IDE still showed “Build website” rather then “Render Website” and “Preview Website”, and would error when we pushed them (because that button was expecting a distill site, not a quarto site). To fix this, we updated the .Rproj file. Clicking on the .Rproj file in the RStudio IDE will open a dialog box where you can click things you want (you can also open these in a text editor or from the GitHub website to see the actual text). To fix this situation with the Build tab: Project Options &gt; Build Tools &gt; Project Build Tools &gt; None.\nLooking at files /posts/_metadata.yml and _quarto.yml helps see where things are defined. For example, to make event post citations appear, we added citation: true to /posts/_metadata.yml and in _quarto.yml under the website key we set site-url: https://openscapes.github.io/events. We deleted footer.html used with distill because footer is now defined in quarto.yml.\n\nPublishing notes\n\nBackground: Our distill site had been set up to output to a docs folder, and had GitHub Settings &gt; Pages set to look there rather gh-pages branch. (Julie note: this was a new-to-me capability when we set up the events distill site in Spring 2021 so I had forgotten that was an option). We’ve inititally kept this same set-up for now with our events page in _quarto.yml: output-dir: docs. However, this is sub-optimal; better to not have to commit and push these files but to instead have a GitHub Action generate them upon a commit. So the following is what we did -\n\nDon’t specify output-dir in _quarto.yml. The output directory default is _site/, which is what we’d like.\nIf you currently have a docs/ folder (like we did as we were experimenting), delete it.\nUpdate .gitignore to ignore _site/. At the same time, we have it ignore caches and a .quarto file:\n/.quarto/\n*_cache/\n_site/\nPush these changes, merge into main.\nOn GitHub.com, in your repo, set up GitHub publishing\nFollow instructions from the explore and setup chapter."
  },
  {
    "objectID": "transition-from-rmarkdown.html#troubleshooting",
    "href": "transition-from-rmarkdown.html#troubleshooting",
    "title": "Transition from RMarkdown",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nGitHub Action fails, says you need RMarkdown but you don’t have R code!\nAnd you changed all .Rmds to .qmds!\nYou likely have a few setup code chunks from RMarkdown, that look like this:\n{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = FALSE)\nYou can find them by opening each of your files and having a look, or use GitHub’s search for the keyword knitr"
  },
  {
    "objectID": "explore.html",
    "href": "explore.html",
    "title": "Explore and setup",
    "section": "",
    "text": "With this tutorial, we have a working example website that we will explore together. We’ll learn a few rules and look for patterns to get an understanding of what things to do to help you start customizing and making it your own. And you can continue to use this website as a reference after the tutorial, along with Quarto documentation.\nWe’ll start our exploration online looking at the website architecture and GitHub repository. Then we’ll setup a copy for ourselves so that we can modify from a working example, which is a great way to learn something new. We’ll set it up so that any modifications (commits) will automatically be republished via GitHub Actions. Subsequent chapters will describe how to modify your repo using different tools (browser, RStudio, Jupyter)."
  },
  {
    "objectID": "explore.html#exploring-online",
    "href": "explore.html#exploring-online",
    "title": "Explore and setup",
    "section": "Exploring online",
    "text": "Exploring online\n\nThe website itself\nThis website has 5 things you can see on the left sidebar:\n\nWelcome\nExploring and setup\nQuarto workflows\nLearning more\nTransition from Rmd\n\nMost of these are pages, but you’ll see that “Quarto Workflows” has an arrow; it is a folder with additional pages inside.\n\n\nThe website’s repo\nLet’s go to this website’s GitHub repository (also called a “repo”), https://github.com/openscapes/quarto-website-tutorial. You can also click there from any page in this tutorial website by clicking the GitHub octocat icon underneath the Openscapes logo in the left navbar (click it holding command on Mac, or control on a PC to open it in a different tab in your browser).\nHave a look at the filenames. We can recognize the names of the webpages we’ve seen above, and they have red arrows marking them in the image below. You’ll see the “quarto-workflows” folder and the rest in this site are .qmd files, which are plain text Quarto files that can combine Markdown text with code. index.qmd is the home page. If you click inside “quarto-workflows” you’ll see a mix of filetypes!\n\n\n\nquarto-website-tutorial GitHub repository with files for webpages marked with red arrows\n\n\nThe _site folder has html files with names that should be familiar: they match the .md files we were just exploring. This folder is where Quarto stores files to build the website."
  },
  {
    "objectID": "explore.html#quarto.yml-intro",
    "href": "explore.html#quarto.yml-intro",
    "title": "Explore and setup",
    "section": "_quarto.yml intro",
    "text": "_quarto.yml intro\nThere is also a _quarto.yml file, which is the website’s configuration file. It is essentially metadata for the website that includes the order that the pages/chapters will be in. This is where you update the organization of your website: which page comes before another. If we compare side-by-side, you’ll see that the pages that appear on our website are listed there.\n\n\n\n_quarto.yml and website side-by-side\n\n\nWe’ll learn more about how to interact with _quarto.yml in Quarto Workflows."
  },
  {
    "objectID": "explore.html#fork-to-your-account",
    "href": "explore.html#fork-to-your-account",
    "title": "Explore and setup",
    "section": "Fork to your account",
    "text": "Fork to your account\nLet’s start with an existing Quarto site and copy it into your space to edit. You’ll need a free GitHub account that you create at github.com (follow this advice about choosing your username).\nFirst, choose an existing website to copy. The simplest option is to start with this site: quarto-website-tutorial.\nOther options of potential interest:\n\n2021-Cloud-Hackathon\n2022-SWOT-Ocean-Cloud-Workshop\nOpenscapes Approach-Guide\n\nNext, follow these steps to fork and setup your repo with GitHub Actions from Gavin Fay, using the repo you chose. These instructions will take ~5 minutes.\nNow you’ve got a copy of your repo of choice in your own GitHub account, and you’re set to start making your own edits. Your GitHub repo is set up with a GitHub Action that will use Quarto to rebuild and republish your site anytime you make a commit: committing will trigger the GitHub Action to rebuild and republish the book.\nNote that the GitHub Action for this book does not include R or Python so those will need to be added if your website relies on code. See https://github.com/r-lib/actions for more details and examples.\n\nDownload instead of fork\nForking might not always be the way to go - you can’t fork into the same GitHub user account or organization so if for example you want to make a copy of 2021-Cloud-Hackathon repo within the same NASA-Openscapes GitHub Organization, you’ll need to download instead of fork. In this case, follow these steps to download and copy into a new repository, and set up the GitHub Action separately.\n\nDownload github repo files\nNavigate to https://github.com/openscapes/quarto-website-tutorial (or any other quarto site repo of choice). Click the green “Code” button and select “Download ZIP”. When it downloads on your computer, unzip the files.\n\n\nCreate a new GitHub repo\nNavigate to your GitHub account or organization, and create a new repository, naming it what you’d like. You’ll need a free GitHub account that you create at github.com (follow this advice about choosing your username). When you’re logged in, github.com will show a green button that says “New” which you’ll also see as you navigate to your username’s repository page.\n\n\nAdd original site files\nTo use the GitHub file uploader, click the button next to the green “Code” button that says “Add file”. Add file &gt; Upload files. Then, on your computer, select all the files in unzipped folder (command-A or control-A), and drag them to the GitHub uploader page. Scroll down to write a commit message, which effectively saves your files when you’re working in the browser.\nNote: if you’re comfortable cloning the new repository and copying files into it locally before committing and pushing back to GitHub, that can be preferable to the uploader, which does have limitations with complex repos (although the uploader works fine with this tutorial repo)."
  },
  {
    "objectID": "explore.html#setup-github-action",
    "href": "explore.html#setup-github-action",
    "title": "Explore and setup",
    "section": "Set up GitHub publishing",
    "text": "Set up GitHub publishing\nIf you’ve used the GitHub uploader, you’ll need to set up GitHub publishing separately. We’ll do this in a few steps: we’ll set up a GitHub Action within your repo, and create a gh-pages branch.\nFirst, the GitHub Action. Go back to your main view of your GitHub repository by clicking on the name of your repository in blue at the top-left (the url in your browser window should say https://github.com/username/repo-name).\nNext to the green code button, click Add file &gt; Create new file. Name it exactly this: .github/workflows/quarto-publish.yml . In detail: start by typing the . with github and when you type the / it will give you a new text box to type workflows (plural!), then another /, and finally, quarto-publish.yml.\nNow you’ll have an empty new file. Paste the following in this empty file - you can click on the top-right of this box to copy all the code inside this code box:\non:\n  push:\n    branches: main\n\nname: Render and Publish\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v2 \n        \n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n        with:\n          # To install LaTeX to build PDF book \n          tinytex: true \n          # uncomment below and fill to pin a version\n          # version: 0.9.600\n      \n      # add software dependencies here\n\n      - name: Publish to GitHub Pages (and render)\n        uses: quarto-dev/quarto-actions/publish@v2\n        with:\n          target: gh-pages\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # this secret is always available for github actions\nCommit this to save your new quarto-publish.yml file. This is your GitHub Action.\nNext, we’ll create a new gh-pages branch. Go back to the main view of your GitHub repository. On the far left from the green “Code” button, click the button that says “main”. In the pull-down menu, type gh-pages - all lowercase, with a hyphen. Click the bold text that says “Create branch: gh-pages from main”.\nNow click on the Settings tab in the top right of your repository. On the left sidebar, click Pages. At the top of Pages under “Source”, select gh-pages root, and press Save. You’ll then see a green highlighted text saying that your site is published at a “github.io” url."
  },
  {
    "objectID": "explore.html#confirm",
    "href": "explore.html#confirm",
    "title": "Explore and setup",
    "section": "Confirm your website is published",
    "text": "Confirm your website is published\nTo confirm that your website is published, go back to your main repository page. You’ll now see an orange dot showing that the GitHub Action is beginning to publish the page.\n\n\n\nOur repo with orange dot indicating in-progress GitHub Action build\n\n\nIf you do not see this orange dot, you might need to make a small commit to trigger the GitHub Actions build. If this is the case, click the pencil on the top-right of the README.md file as circled in the image below, add some small edit (like a space after a period), and scroll down to click commit. Now you should see the orange dot.\n\n\n\n\n\nWhen your orange do becomes a green check, you can go inspect your published site at “https://username.github.io/your-repo). For example: https://openscapes.github.io/quarto-website-tutorial.\n\n\n\nOur repo with green check indicating successful GitHub Action build"
  },
  {
    "objectID": "explore.html#renaming-your-repo",
    "href": "explore.html#renaming-your-repo",
    "title": "Explore and setup",
    "section": "Renaming your repo",
    "text": "Renaming your repo\nIf you’d like to rename your repo, go to Settings and the option to rename is on the top of the main settings page."
  },
  {
    "objectID": "explore.html#onward",
    "href": "explore.html#onward",
    "title": "Explore and setup",
    "section": "Onward!",
    "text": "Onward!\nNow you are ready to start editing and publishing! The next chapter describes how starting off from the browser, using Markdown."
  },
  {
    "objectID": "quarto-workflows/jupyter.html",
    "href": "quarto-workflows/jupyter.html",
    "title": "From Jupyter",
    "section": "",
    "text": "You can interact with Quarto through JupyterLab or JupyterHub. Your Jupyter setup will involve .ipynb notebooks and the command line. Quarto’s JupyterLab tutorials has great instructions on getting started with JupyterLab, including computations and authoring.\nHere we will demonstrate how to work with this Quarto tutorial site in JupyterHub and add a Jupyter Notebook (.ipynb file). This example uses the NASA-Openscapes JupyterHub that already has all python environments as well as Quarto installed."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#setup",
    "href": "quarto-workflows/jupyter.html#setup",
    "title": "From Jupyter",
    "section": "Setup",
    "text": "Setup\n\nJupyterHub\nOur JupyterHub is already setup with python environments as well as Quarto (through nasa-openscapes/corn), so there is no further installation required.\n\n\nClone your repo\nYou’ll start by cloning your repository into JupyterHub. Do this by opening a terminal (File &gt; New &gt; Terminal). In the Terminal, git clone your repository and cd into it:\ngit clone https://github.com/openscapes/quarto-website-tutorial\ncd quarto-website-tutorial\n\n\nInstall Quarto\nNot needed - Quarto is already installed on the NASA-Openscapes JupyterHub! But to install elsewhere you would do so from https://quarto.org/docs/get-started/.\nQuarto is a Command Line Interface (CLI), like git. Once download is complete, follow the installation prompts on your computer like you do for other software. You won’t see an application to click on when it is installed.\nNote for Mac users: If you do not have administrative privileges, please select “Install for me only” during the Destination Selection installation step (you will first click on “Change Install Location” at the Installation Type step).\nYou can check to confirm that Quarto is installed properly from the command line:\nquarto check install\n\n\n\n\n\n\nAdditional checks\n\n\n\n\n\nYou can also run:\n\nquarto check knitr to locate R, verify we have the rmarkdown package, and do a basic render\nquarto check jupyter to locate Python, verify we have Jupyter, and do a basic render\nquarto check to run all of these checks together\n\n\n\n\n\n\n\n\n\n\nHistorical aside: Install Quarto in a docker container\n\n\n\n\n\nIn Summer 2021 some NASA Mentors trying to install quarto locally was not an option, but they were able to install it inside a container using the following Dockerfile:\n#| fold: true\n#| summary: \"Show the Dockerfile\"\n\n##############################\n# This Dockerfile installs quarto and then runs quarto serve against the\n# internal /home/quarto/to_serve.\n#\n# BUILD\n# -----\n# To build this container, run\n#\n#     docker build -t quarto_serve .\n#\n# Add the --no-cache option to force docker to build fresh and get the most\n# recent version of quarto.\n#\n#\n# RUN\n# ---\n# 1. Find the directory you want quarto to serve. Let's call this /PATH/TO/earthdata-cloud-cookbook.\n# 2. Run docker:\n#\n#     docker run --rm -it -p 4848:4848 -v /PATH/TO/earthdata-cloud-cookbook:/home/quarto/to_serve quarto_serve\n#\n# 3. Open your browser and go to http://127.0.0.1:4848/\n#\n##############################\n\nFROM ubuntu:hirsute\n\n######\n# Install some command line tools we'll need\n######\nRUN apt-get update\nRUN apt-get -y install wget\nRUN apt-get -y install gdebi-core\nRUN apt-get -y install git\n\n\n######\n# Install quarto (https://quarto.org/)\n######\n\n# This is a quick and dirty way of getting the newest version number from\n# https://github.com/quarto-dev/quarto-cli/releases/latest. What's happening is\n# we're pulling the version number out of the redirect URL. This will end up\n# with QVER set to something like 0.2.11.\nRUN QVER=`wget --max-redirect 0 https://github.com/quarto-dev/quarto-cli/releases/latest 2&gt;&1 | grep \"Location\" | sed 's/L.*tag\\/v//' | sed 's/ .*//'` \\\n    && wget -O quarto.deb \"https://github.com/quarto-dev/quarto-cli/releases/download/v$QVER/quarto-$QVER-amd64.deb\"\nRUN gdebi -n quarto.deb\n\n# Run this to make sure quarto installed correctly\nRUN quarto check install\n\n\n######\n# Create a non-root user called quarto\n######\nRUN useradd -ms /bin/bash quarto\nUSER quarto\nRUN mkdir /home/quarto/to_serve\nWORKDIR /home/quarto/to_serve\n\n\n######\n# Start quarto serve\n######\n\nCMD quarto serve --no-browse --host 0.0.0.0 --port 4848"
  },
  {
    "objectID": "quarto-workflows/jupyter.html#quarto-preview",
    "href": "quarto-workflows/jupyter.html#quarto-preview",
    "title": "From Jupyter",
    "section": "Quarto preview",
    "text": "Quarto preview\nLet’s start off by previewing our quarto site locally. In Terminal, type quarto preview, which will provide a URL with a preview of our site!\nquarto preview\n# Preparing to preview\n# Watching files for changes\n# Browse at https://openscapes.2i2c.cloud/user/jules32/proxy/4593/\nCopy this URL into another browser window; and arrange them so you can see them both. I make a bit more space in Jupyter by collapsing the left file menu by clicking on the file icon at the top of the left sidebar.\n\n\n\n\n\n\nMake a small change and preview it\nNow we’ll be able to see live changes in the preview as we edit in our .md files. Let’s try it: Change the date in index.md by opening it from the file directory. Change to today’s date, and save. Your preview window will refresh automatically! If it does not, you can also refresh the page manually. The refreshed previewed site will now display your changes!"
  },
  {
    "objectID": "quarto-workflows/jupyter.html#create-a-new-.ipynb-page",
    "href": "quarto-workflows/jupyter.html#create-a-new-.ipynb-page",
    "title": "From Jupyter",
    "section": "Create a new .ipynb page",
    "text": "Create a new .ipynb page\nLet’s add a new page to our site. Instead of an .md file like the others, let’s add a .ipynb file.\nFile &gt; New &gt; Notebook. Accept the default kernel by clicking Select.\n\nFirst chunk: raw yaml\nBy default, this Notebook will give us a first chunk that is code. Let’s change it to raw so that we can write our yaml at the top.\n\n\n\n\n\nIn our Raw code chunk, let’s write the title of this document. We need three dashes --- on separate lines preceding and following the title:, which you can name as you’d like.\n---\ntitle: Python Example\n---\n\n\nSecond chunk: Markdown\nLet’s add a new chunk that is Markdown so we can write some description of what this page will be.\nClick the + symbol at the top of the document, and this will add a new chunk, which by default again is a Code chunk. Change it to a Markdown Chunk following the steps we did above when switching to Raw.\nHere, write a little bit of text in Markdown. Since your title is effectively a level-1 header, avoid using level-1 headers in the rest of your document. Here is some example text I wrote:\n## Introduction\n\nThis example has some Python code that will be a part of our Quarto site.\n\n\nThird chunk: Code\nNow let’s create a new chunk with the default Code setting.\nPaste the following code (or write some of your own to test):\n#| label: fig-polar\n#| fig-cap: \"A line plot on a polar axis\"\nimport numpy as np\nimport matplotlib.pyplot as plt\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\nNow, go ahead and execute this code chunk like you normally would, by clicking the cursor in a code block and clicking the sideways “play” triangle to run the selected cells (and advance to the next cell). This code produces a plot.\nNote that the code runs as it normally would; the code options in the comments are just comments.\n\n\nSave your file\nSave your document - I’ll call mine python-example.ipynb in the main repository."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#update-_quarto.yml",
    "href": "quarto-workflows/jupyter.html#update-_quarto.yml",
    "title": "From Jupyter",
    "section": "Update _quarto.yml",
    "text": "Update _quarto.yml\nNow we’ll add python-example.ipynb to our _quarto.yml file; this is where we register of all files to include in our site. Let’s add it after the section called “Basic Workflows”.\nOpen _quarto.yml by clicking on it from the file directory.\nScroll down to review the current contents in the sidebar: section. It’s there we see all the file arrangement that we see in the previewed site.\nAdd - python-example.ipynb to line 46, making sure that your indentation aligns with the other pages.\n\n\n\n\n\nYou’ll see that our new page shows up in our Preview, and the code is executed since we did that in the Jupyter Notebook itself. By default, Quarto will not execute code chunks since your computations will likely become more complex and you will want to control when they are executed (or “run”).\nSince Quarto is still previewing our website and the python-example.ipynb, the plot also displays in the notebook after the code is run and the file is saved, as shown below.\n\n\n\n\n\nSo, your normal workflow for creating and running code blocks in your Jupyter Notebook is the same one you’ll use as Quarto displays the preview."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#quarto-render",
    "href": "quarto-workflows/jupyter.html#quarto-render",
    "title": "From Jupyter",
    "section": "Quarto render",
    "text": "Quarto render\nSo far we have used Quarto preview to view our website as we develop it. Quarto render will build the html elements of the website that we can see when we preview. Rendering will format the markdown text and code nicely as a website (or however is indicated in the _quarto.yml).\nBy default, Quarto render does not execute code in a Jupyter notebook. It will never run .ipynb files unless you tell it to.\n\nRender whole notebook\nIf you would like it to specifically execute code in a Jupyter notebook, you can do so in Terminal.\nOur Terminal is still busy previewing our website, so let’s open a new Terminal.\nFile &gt; New &gt; Terminal. Then type:\ncd quarto-website-tutorial\nquarto render python-example.ipynb --execute"
  },
  {
    "objectID": "quarto-workflows/jupyter.html#authoring-tips",
    "href": "quarto-workflows/jupyter.html#authoring-tips",
    "title": "From Jupyter",
    "section": "Authoring tips",
    "text": "Authoring tips\nQuarto.org has details about authoring, including specific instructions about authoring in Jupyter: quarto.org/docs/reference/cells/cells-jupyter."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#commit-and-push",
    "href": "quarto-workflows/jupyter.html#commit-and-push",
    "title": "From Jupyter",
    "section": "Commit and push!",
    "text": "Commit and push!\nCommitting and pushing will make the changes you see locally live on your website (using the GitHub Action we set up earlier)."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#troubleshooting",
    "href": "quarto-workflows/jupyter.html#troubleshooting",
    "title": "From Jupyter",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nMy changes don’t show up in preview\nMake sure you’ve saved your file! There might be a slight delay depending on your JupyterHub/Lab setup.\n\n\nQuarto render hangs / does not complete\nCheck the specific notebook, are there any `—` throughout to denote line breaks rather than yaml? They might be causing the issue; consider deleting those.\nAlso check how long the first raw cell is. Are there level-1 headers (#)? Try removing them."
  },
  {
    "objectID": "quarto-workflows/index.html",
    "href": "quarto-workflows/index.html",
    "title": "Quarto workflows",
    "section": "",
    "text": "How do you work in Quarto? You can use whichever tool you’re comfortable with (RStudio, Jupyter, GitHub, VS Code, etc). Developing your quarto site will have the same basic workflow, no matter which tool you use. It is very iterative, and each is explored more below.\n\nAuthoring: write text, code, images, etc in a file. Supported files include .md, .Rmd, .qmd, .ipynb…\nUpdate _quarto.yml as needed (for example, if you’ve created a new file you’d like included in your site)\nRender individual files and/or the whole website\nRepeat, repeat, repeat\nCommit and push your website to GitHub, your updates will publish automatically!\nRepeat all of the above to make the website as you’d like!\n\nNote: if editing from your internet browser we won’t render in Step 3. That step will not be separate, but combined with Step 5, which will only require a commit, not a push."
  },
  {
    "objectID": "quarto-workflows/index.html#basic-workflow",
    "href": "quarto-workflows/index.html#basic-workflow",
    "title": "Quarto workflows",
    "section": "",
    "text": "How do you work in Quarto? You can use whichever tool you’re comfortable with (RStudio, Jupyter, GitHub, VS Code, etc). Developing your quarto site will have the same basic workflow, no matter which tool you use. It is very iterative, and each is explored more below.\n\nAuthoring: write text, code, images, etc in a file. Supported files include .md, .Rmd, .qmd, .ipynb…\nUpdate _quarto.yml as needed (for example, if you’ve created a new file you’d like included in your site)\nRender individual files and/or the whole website\nRepeat, repeat, repeat\nCommit and push your website to GitHub, your updates will publish automatically!\nRepeat all of the above to make the website as you’d like!\n\nNote: if editing from your internet browser we won’t render in Step 3. That step will not be separate, but combined with Step 5, which will only require a commit, not a push."
  },
  {
    "objectID": "quarto-workflows/index.html#authoring",
    "href": "quarto-workflows/index.html#authoring",
    "title": "Quarto workflows",
    "section": "Authoring",
    "text": "Authoring\nAs an author, you have a lot of options of how your text will be formatted, arranged, and interlinked. You will be writing in Markdown, which is a lightweight text formatting language. The Quarto documentation about authoring introduces markdown-basics that will get you started. Also see Mine Çetinkaya-Rundel’s A Quarto tip a day.\nEach page of our site has a similar first few lines - this YAML, like we saw in our _quarto.yml and it is indicated by two sets of 3 dashes --- :\n---\ntitle: My title\n---\nYou’re able to add more features to individual pages by including it in the YAML, which for the most part here only includes a title. See Quarto excecution options for more information of what you can include in the YAML."
  },
  {
    "objectID": "quarto-workflows/index.html#update-_quarto.yml",
    "href": "quarto-workflows/index.html#update-_quarto.yml",
    "title": "Quarto workflows",
    "section": "Update _quarto.yml",
    "text": "Update _quarto.yml\nLet’s have a closer look at the _quarto.yml file.\nThis type of file (.yml or .yaml) is written in YAML (“Yet Another Markup Language”). You’ll be able to shift the arrangement of webpages by reordering/adding/deleting them in the _quarto.yml file following the patterns you see in this example.\n\n\n\n_quarto.yml and website side-by-side\n\n\nNotice that there are multiple ways in the _quarto.yml for you to include a file in your website. For example, in the above image, the “First Observations” we see in the left sidebar of the published website (right image) is represented in _quarto.yml (left image) over two lines, with line 36 indicating the file reference and line 37 indicating the text to show up in the left sidebar. However, “From RStudio” is only represented in one line of _quarto.yml, on line 43. This represents two strategies for including a file in your website. By default, the title of a specified file will show up in the website’s sidebar, which is what is happening with the “From RStudio” example. If you would like more control over what is written in the sidebar vs the title of your files, then the approach we took with “First Observations” is what you’ll want to do: you’ll see that only “First Observations” shows up in the sidebar as we specified in _quarto.yml, but the page’s title says “First Observations & Setup” (which in our preference was too long for the sidebar).\n\n\n\n\n\n\nNote\n\n\n\nAs you modify _quarto.yml, the most important thing to know is that spacing matters. Pay attention to whether text is indented by one, two, four, or other spaces, and make sure you follow it; if your site is not looking as expected it is likely a silent error in your YAML. Some text editors like RStudio provide debugging support for YAML and are highly recommended to save you time and heartache."
  },
  {
    "objectID": "quarto-workflows/index.html#install-quarto",
    "href": "quarto-workflows/index.html#install-quarto",
    "title": "Quarto workflows",
    "section": "Install Quarto",
    "text": "Install Quarto\nhttps://quarto.org/docs/get-started/ describes how to install Quarto, which will depend on your operating system. We’ll walk through installation for each tool in the next chapters."
  },
  {
    "objectID": "machine-learning/focal-loss.html",
    "href": "machine-learning/focal-loss.html",
    "title": "Focal loss - handle class imbalance",
    "section": "",
    "text": "Hàm mất mát Focal là một sự cải tiến so với hàm mất mát cross-entropy tiêu chuẩn cho phân loại nhị phân và đa lớp. Nó được giới thiệu trong bài báo có tiêu đề “Focal Loss for Dense Object Detection” của Tsung-Yi Lin và cộng sự, và chủ yếu được thiết kế cho các nhiệm vụ phát hiện đối tượng để giải quyết bài toán mất cân bằng giữa các lớp (class imbalance).\nÝ chính đằng sau hàm mất mát Focal là giảm trọng số đóng góp của các ví dụ dễ dàng và tập trung vào những ví dụ khó. Điều này giúp ngăn chặn số lượng lớn các ví dụ tiêu cực dễ dàng từ việc áp đặt lên bộ phát hiện trong quá trình đào tạo.\nCông thức cho hàm mất mát Focal cho phân loại nhị phân là:\n\\[ \\text{FL}(p_t) = -\\alpha_t (1 - p_t)^\\gamma \\log(p_t) \\]\nTrong đó:\n\n$ p_t $ là xác suất của lớp đúng (true class). Nếu nhãn lớp đúng là 1, thì $ p_t $ là xác suất dự đoán của mô hình cho lớp 1; nếu nhãn lớp đúng là 0, thì $ p_t = 1 - $ xác suất dự đoán của mô hình cho lớp 1.\n$ _t $ là một yếu tố cân bằng. Thông thường đặt nằm giữa 0 và 1. Số này được sử dụng để xử lý mất cân bằng lớp.\n$ $ là tham số tập trung (focusing parameter) mục đích điều chỉnh mức độ tập trung vào lớp dễ dàng phân loại. Khi $ = 0 $, hàm mất mát Focal tương đương với hàm mất mát cross-entropy. Khi $ $ tăng, hiệu ứng của yếu tố điều chỉnh trở nên rõ ràng hơn.\n\nLợi thế chính của hàm mất mát Focal là nó đưa ra nhiều trọng số hơn cho các ví dụ bị phân loại sai và ít trọng số hơn cho các ví dụ được phân loại tốt. Điều này giúp trong các tình huống mà một số lớp bị đại diện ít hơn hoặc khi mô hình có khả năng bị áp đặt bởi các ví dụ tiêu cực dễ dàng.\n\n\n\nMục đích: $ $ được sử dụng trong hàm mất mát Focal để xử lý sự mất cân bằng lớp bằng cách điều chỉnh mất mát cho các lớp dương và âm một cách khác nhau. Nó cung cấp một sự cân bằng giữa tầm quan trọng của lớp dương và lớp âm trong việc tính toán mất mát.\nẢnh hưởng lên Giá trị Mất mát:\n\nĐối với lớp dương (tức là khi nhãn thực $ y = 1 $): Giá trị mất mát được nhân với hệ số $ $.\nĐối với lớp âm (tức là khi nhãn thực $ y = 0 $): Giá trị mất mát được nhân với hệ số $ 1 - $.\n\nPhạm vi Giá trị:\n\nThông thường, $ $ nằm trong khoảng [0, 1].\nGiá trị $ $ càng gần 1 càng làm cho mất mát lớp dương được tăng cường và mất mát cho lớp âm được giảm đi.\nNgược lại, một giá trị $ $ gần 0 sẽ nhấn mạnh hơn đến lớp âm.\n\nLợi ích:\n\nBằng cách điều chỉnh $ $, người ta có thể cung cấp trọng số nhiều hơn cho các lớp được đại diện ít hơn. Điều này có thể đặc biệt hữu ích trong các tình huống có sự mất cân bằng lớp nghiêm trọng, như trong các nhiệm vụ phát hiện đối tượng khi số lượng các ví dụ âm vượt trội so với các ví dụ dương.\nNó đảm bảo rằng mô hình không thiên vị về lớp có nhiều quan sát hơn và xem xét cả hai lớp khi cập nhật trọng số trong quá trình huấn luyện.\n\nThiết lập $ $:\n\nTrong một số trường hợp, $ $ có thể được thiết lập dựa trên phân phối lớp nghịch đảo. Ví dụ, nếu 80% các ví dụ là âm và 20% là dương, người ta có thể đặt $ $ thành 0,2 cho lớp âm và 0,8 cho lớp dương.\nTrong những trường hợp khác, giá trị của $ $ có thể được xác định thông qua kiểm định chéo (cross-validation) hoặc các phương pháp điều chỉnh tham số khác.\n\n\nTóm lại, tham số $ $ trong hàm mất mát Focal cung cấp một cơ chế để xử lý sự mất cân bằng lớp bằng cách điều chỉnh mất mát cho các ví dụ dương và âm một cách khác nhau. Nó đảm bảo rằng cả hai lớp chính và phụ đều được đại diện đầy đủ trong quá trình đào tạo của mô hình.\n\n\n\n$ $ được gọi là “tham số tập trung”. Nó đóng một vai trò quan trọng trong việc xác định mức độ mà mô hình nên tập trung vào các lớp bị phân loại sai so với những lớp được phân loại đúng.\nTác động của nó:\n\nMục đích: Mục đích chính của tham số $ $ trong hàm mất mát Focal là giảm ảnh hưởng của các lớp dễ phân loại và tăng tầm quan trọng của việc hiệu chỉnh các lớp bị phân loại sai. Điều này đặc biệt hữu ích trong các tình huống mà tập dữ liệu có sự mất cân bằng giữa các lớp.\nTác động của việc Thay đổi $ $: Thuật ngữ $ (1 - p_t)^$ trong hàm mất mát Focal là yếu tố điều chỉnh. Ở đây, $ p_t $ đại diện cho xác suất dự đoán của lớp đúng.\n\nNếu $ p_t $ gần bằng 1, nghĩa là ví dụ dễ dàng được phân loại, và $ (1 - p_t)^$ sẽ gần bằng 0, đặc biệt khi $ &gt; 0 $.\nNếu $ p_t $ xa 1 (tức là dự đoán là không chính xác hoặc không chắc chắn), thì $ (1 - p_t)^$ sẽ lớn hơn, tăng ảnh hưởng của ví dụ đó lên hàm mất mát.\n$ = 0 $: Hàm mất mát Focal giảm xuống còn bằng hàm mất mát cross-entropy tiêu chuẩn, vì yếu tố điều chỉnh trở thành 1 cho tất cả các ví dụ.\n$ &gt; 0 $: Tăng trọng số của các lớp khó phân loại và giảm trọng số của những lớp dễ phân loại. $ $ càng lớn, mô hình càng tập trung nhiều vào các lớp khó.\n\nLợi ích: Bằng cách điều chỉnh $ $, hàm mất mát Focal cho phép các mô hình, đặc biệt trong các nhiệm vụ phát hiện đối tượng, trở nên mạnh mẽ hơn trước số lượng lớn các lớp dễ. Thay vì tiêu tốn tài nguyên tính toán cho các lớp dễ dàng, mô hình tập trung nhiều hơn vào các lớp khó, thường chứa nhiều thông tin hơn.\n\nTóm lại, tham số $ $ trong hàm mất mát Focal cung cấp một cơ chế để nhấn mạnh việc học từ các lớp bị phân loại sai so với những lớp dễ phân loại. Đó là một công cụ để xử lý sự mất cân bằng lớp và đảm bảo rằng mô hình chú ý nhiều hơn đến các lớp mà nó phân loại sai."
  },
  {
    "objectID": "machine-learning/focal-loss.html#focal-loss",
    "href": "machine-learning/focal-loss.html#focal-loss",
    "title": "Focal loss - handle class imbalance",
    "section": "",
    "text": "Hàm mất mát Focal là một sự cải tiến so với hàm mất mát cross-entropy tiêu chuẩn cho phân loại nhị phân và đa lớp. Nó được giới thiệu trong bài báo có tiêu đề “Focal Loss for Dense Object Detection” của Tsung-Yi Lin và cộng sự, và chủ yếu được thiết kế cho các nhiệm vụ phát hiện đối tượng để giải quyết bài toán mất cân bằng giữa các lớp (class imbalance).\nÝ chính đằng sau hàm mất mát Focal là giảm trọng số đóng góp của các ví dụ dễ dàng và tập trung vào những ví dụ khó. Điều này giúp ngăn chặn số lượng lớn các ví dụ tiêu cực dễ dàng từ việc áp đặt lên bộ phát hiện trong quá trình đào tạo.\nCông thức cho hàm mất mát Focal cho phân loại nhị phân là:\n\\[ \\text{FL}(p_t) = -\\alpha_t (1 - p_t)^\\gamma \\log(p_t) \\]\nTrong đó:\n\n$ p_t $ là xác suất của lớp đúng (true class). Nếu nhãn lớp đúng là 1, thì $ p_t $ là xác suất dự đoán của mô hình cho lớp 1; nếu nhãn lớp đúng là 0, thì $ p_t = 1 - $ xác suất dự đoán của mô hình cho lớp 1.\n$ _t $ là một yếu tố cân bằng. Thông thường đặt nằm giữa 0 và 1. Số này được sử dụng để xử lý mất cân bằng lớp.\n$ $ là tham số tập trung (focusing parameter) mục đích điều chỉnh mức độ tập trung vào lớp dễ dàng phân loại. Khi $ = 0 $, hàm mất mát Focal tương đương với hàm mất mát cross-entropy. Khi $ $ tăng, hiệu ứng của yếu tố điều chỉnh trở nên rõ ràng hơn.\n\nLợi thế chính của hàm mất mát Focal là nó đưa ra nhiều trọng số hơn cho các ví dụ bị phân loại sai và ít trọng số hơn cho các ví dụ được phân loại tốt. Điều này giúp trong các tình huống mà một số lớp bị đại diện ít hơn hoặc khi mô hình có khả năng bị áp đặt bởi các ví dụ tiêu cực dễ dàng.\n\n\n\nMục đích: $ $ được sử dụng trong hàm mất mát Focal để xử lý sự mất cân bằng lớp bằng cách điều chỉnh mất mát cho các lớp dương và âm một cách khác nhau. Nó cung cấp một sự cân bằng giữa tầm quan trọng của lớp dương và lớp âm trong việc tính toán mất mát.\nẢnh hưởng lên Giá trị Mất mát:\n\nĐối với lớp dương (tức là khi nhãn thực $ y = 1 $): Giá trị mất mát được nhân với hệ số $ $.\nĐối với lớp âm (tức là khi nhãn thực $ y = 0 $): Giá trị mất mát được nhân với hệ số $ 1 - $.\n\nPhạm vi Giá trị:\n\nThông thường, $ $ nằm trong khoảng [0, 1].\nGiá trị $ $ càng gần 1 càng làm cho mất mát lớp dương được tăng cường và mất mát cho lớp âm được giảm đi.\nNgược lại, một giá trị $ $ gần 0 sẽ nhấn mạnh hơn đến lớp âm.\n\nLợi ích:\n\nBằng cách điều chỉnh $ $, người ta có thể cung cấp trọng số nhiều hơn cho các lớp được đại diện ít hơn. Điều này có thể đặc biệt hữu ích trong các tình huống có sự mất cân bằng lớp nghiêm trọng, như trong các nhiệm vụ phát hiện đối tượng khi số lượng các ví dụ âm vượt trội so với các ví dụ dương.\nNó đảm bảo rằng mô hình không thiên vị về lớp có nhiều quan sát hơn và xem xét cả hai lớp khi cập nhật trọng số trong quá trình huấn luyện.\n\nThiết lập $ $:\n\nTrong một số trường hợp, $ $ có thể được thiết lập dựa trên phân phối lớp nghịch đảo. Ví dụ, nếu 80% các ví dụ là âm và 20% là dương, người ta có thể đặt $ $ thành 0,2 cho lớp âm và 0,8 cho lớp dương.\nTrong những trường hợp khác, giá trị của $ $ có thể được xác định thông qua kiểm định chéo (cross-validation) hoặc các phương pháp điều chỉnh tham số khác.\n\n\nTóm lại, tham số $ $ trong hàm mất mát Focal cung cấp một cơ chế để xử lý sự mất cân bằng lớp bằng cách điều chỉnh mất mát cho các ví dụ dương và âm một cách khác nhau. Nó đảm bảo rằng cả hai lớp chính và phụ đều được đại diện đầy đủ trong quá trình đào tạo của mô hình.\n\n\n\n$ $ được gọi là “tham số tập trung”. Nó đóng một vai trò quan trọng trong việc xác định mức độ mà mô hình nên tập trung vào các lớp bị phân loại sai so với những lớp được phân loại đúng.\nTác động của nó:\n\nMục đích: Mục đích chính của tham số $ $ trong hàm mất mát Focal là giảm ảnh hưởng của các lớp dễ phân loại và tăng tầm quan trọng của việc hiệu chỉnh các lớp bị phân loại sai. Điều này đặc biệt hữu ích trong các tình huống mà tập dữ liệu có sự mất cân bằng giữa các lớp.\nTác động của việc Thay đổi $ $: Thuật ngữ $ (1 - p_t)^$ trong hàm mất mát Focal là yếu tố điều chỉnh. Ở đây, $ p_t $ đại diện cho xác suất dự đoán của lớp đúng.\n\nNếu $ p_t $ gần bằng 1, nghĩa là ví dụ dễ dàng được phân loại, và $ (1 - p_t)^$ sẽ gần bằng 0, đặc biệt khi $ &gt; 0 $.\nNếu $ p_t $ xa 1 (tức là dự đoán là không chính xác hoặc không chắc chắn), thì $ (1 - p_t)^$ sẽ lớn hơn, tăng ảnh hưởng của ví dụ đó lên hàm mất mát.\n$ = 0 $: Hàm mất mát Focal giảm xuống còn bằng hàm mất mát cross-entropy tiêu chuẩn, vì yếu tố điều chỉnh trở thành 1 cho tất cả các ví dụ.\n$ &gt; 0 $: Tăng trọng số của các lớp khó phân loại và giảm trọng số của những lớp dễ phân loại. $ $ càng lớn, mô hình càng tập trung nhiều vào các lớp khó.\n\nLợi ích: Bằng cách điều chỉnh $ $, hàm mất mát Focal cho phép các mô hình, đặc biệt trong các nhiệm vụ phát hiện đối tượng, trở nên mạnh mẽ hơn trước số lượng lớn các lớp dễ. Thay vì tiêu tốn tài nguyên tính toán cho các lớp dễ dàng, mô hình tập trung nhiều hơn vào các lớp khó, thường chứa nhiều thông tin hơn.\n\nTóm lại, tham số $ $ trong hàm mất mát Focal cung cấp một cơ chế để nhấn mạnh việc học từ các lớp bị phân loại sai so với những lớp dễ phân loại. Đó là một công cụ để xử lý sự mất cân bằng lớp và đảm bảo rằng mô hình chú ý nhiều hơn đến các lớp mà nó phân loại sai."
  },
  {
    "objectID": "machine-learning/focal-loss.html#ví-dụ",
    "href": "machine-learning/focal-loss.html#ví-dụ",
    "title": "Focal loss - handle class imbalance",
    "section": "Ví dụ",
    "text": "Ví dụ\n\nTunning alpha and gamma\n\nimport numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nimport optuna\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\nfrom lightgbm.callback import record_evaluation\noptuna.logging.set_verbosity(optuna.logging.WARNING)\n\n# Generate imbalanced data using make_classification\nX, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10, weights=[0.99, 0.01], random_state=42)  # 99% of class 0 and 1% of class 1\nX_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n\n# Define Focal Loss for LightGBM\ndef focal_loss_lgb(y_pred, dtrain, alpha, gamma):\n    a, g = alpha, gamma\n    y_true = dtrain.get_label()\n    p = 1 / (1 + np.exp(-y_pred))\n    loss = -(a * y_true + (1 - a) * (1 - y_true)) * ((1 - (y_true * p + (1 - y_true) * (1 - p))) ** g) * (y_true * np.log(p) + (1 - y_true) * np.log(1 - p))\n    return 'focal_loss', np.mean(loss), False\n\n# Gini coefficient\ndef gini(y_true, y_pred):\n    return 2 * roc_auc_score(y_true, y_pred) - 1\n\n# Optuna study for tuning alpha and gamma\ndef objective(trial):\n    # Parameters to be tuned\n    alpha = trial.suggest_float('alpha', 0.01, 1)\n    gamma = trial.suggest_float('gamma', 0.1, 5)\n    \n    train_set = lgb.Dataset(X_train, y_train)\n    val_set = lgb.Dataset(X_val, y_val, reference=train_set)\n\n    param = {\n        'objective': 'binary',\n        'metric': 'custom',\n        'verbosity': -1,\n        'boosting_type': 'gbdt',\n        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0),\n        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n    }\n\n    # Using record_evaluation to capture validation results without printing\n    evals_result = {}\n    model = lgb.train(param, \n                      train_set, \n                      valid_sets=[val_set], \n                      feval=lambda preds, dtrain: focal_loss_lgb(preds, dtrain, alpha, gamma), \n                      callbacks=[record_evaluation(evals_result)])\n    \n    preds = model.predict(X_val)\n    return gini(y_val, preds)\n\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100) \n\n# Results\nbest_params = study.best_params\nbest_score = study.best_value\n\n# Plotting\nalphas = [trial.params['alpha'] for trial in study.trials]\ngammas = [trial.params['gamma'] for trial in study.trials]\nscores_focal = [trial.value for trial in study.trials]\nplt.figure(figsize=(12, 5))\nplt.scatter(alphas, scores_focal, color='blue', label='Alpha')\nplt.scatter(gammas, scores_focal, color='red', label='Gamma')\nplt.xlabel('Parameter Value')\nplt.ylabel('Gini Score')\nplt.title('Effect of Alpha and Gamma on Gini Score')\nplt.legend()\nplt.show()\n\nprint(f\"Best Gini score: {best_score}\")\nprint(f\"Best parameters: {best_params}\")\n\n\n\n\nBest Gini score: 0.7631133671742809\nBest parameters: {'alpha': 0.45019195857112326, 'gamma': 0.4919531053413074, 'lambda_l1': 6.640753524365382, 'lambda_l2': 9.081726977645413, 'num_leaves': 21, 'feature_fraction': 0.9362220967011345, 'bagging_fraction': 0.4744110361566192, 'bagging_freq': 2, 'min_child_samples': 12}\n\n\n\n# Optuna study for tuning alpha and gamma\ndef objective(trial):\n    \n    train_set = lgb.Dataset(X_train, y_train)\n    val_set = lgb.Dataset(X_val, y_val, reference=train_set)\n\n    params_ce = {\n        'objective': 'binary',\n        'metric': 'binary_logloss',\n        'verbosity': -1,\n        'boosting_type': 'gbdt',\n        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0),\n        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n    }\n\n    # Using record_evaluation to capture validation results without printing\n    evals_result_ce = {}\n    model_ce = lgb.train(params_ce, train_set, valid_sets=[val_set], callbacks=[record_evaluation(evals_result_ce)])\n    preds_ce = model_ce.predict(X_val)    \n    return gini(y_val, preds_ce)\n\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100) \n\n# Results\nbest_params = study.best_params\nbest_score = study.best_value\nscores_ce = [trial.value for trial in study.trials]\nprint(f\"Best Gini score: {best_score}\")\nprint(f\"Best parameters: {best_params}\")\n\nBest Gini score: 0.7445008460236886\nBest parameters: {'lambda_l1': 5.045686905737897, 'lambda_l2': 8.682377409692112, 'num_leaves': 158, 'feature_fraction': 0.7953399252370615, 'bagging_fraction': 0.43225443468376873, 'bagging_freq': 3, 'min_child_samples': 16}\n\n\n==&gt; Sử dụng focal loss sau 100 lần thử thì tìm được mô hình có gini tốt hơn so với sử dụng cross entropy\n\n# Plotting\nplt.figure(figsize=(12, 6))\nplt.plot(scores_ce, label='Cross-Entropy', color='red')\nplt.plot(scores_focal, label='Focal Loss', color='blue')\nplt.xlabel('Trial')\nplt.ylabel('ROC AUC Score')\nplt.title('Comparison of Focal Loss and Cross-Entropy over Trials')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n# Initialize lists to store results\nfocal_scores = []\nce_scores = []\nimbalance_ratios = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n\nfor ratio in imbalance_ratios:\n    # Generate imbalanced data\n    X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10, weights=[1-ratio, ratio], random_state=42)\n    X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n    \n    train_set = lgb.Dataset(X_train, y_train)\n    val_set = lgb.Dataset(X_val, y_val, reference=train_set)\n    \n    # Train with Focal Loss\n    params_focal = {\n        'objective': 'binary',\n        'metric': 'custom',\n        'boosting_type': 'gbdt'\n    }\n    \n    alpha_value = 0.25\n    gamma_value = 2.0\n    evals_result_focal = {}    \n    model_focal = lgb.train(params_focal, train_set, valid_sets=[val_set], \n                        feval=lambda preds, dtrain: focal_loss_lgb(preds, dtrain, alpha_value, gamma_value), \n                        callbacks=[record_evaluation(evals_result_focal)])\n    preds_focal = model_focal.predict(X_val)\n    roc_focal = roc_auc_score(y_val, preds_focal)\n    \n    # Train with Cross-Entropy\n    params_ce = {\n        'objective': 'binary',\n        'metric': 'binary_logloss',\n        'boosting_type': 'gbdt'\n    }\n    \n    evals_result_ce = {} \n    model_ce = lgb.train(params_ce, train_set, valid_sets=[val_set], callbacks=[record_evaluation(evals_result_ce)])\n    preds_ce = model_ce.predict(X_val)\n    roc_ce = roc_auc_score(y_val, preds_ce)\n    \n    # Store results\n    focal_scores.append(roc_focal)\n    ce_scores.append(roc_ce)\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.plot(imbalance_ratios, focal_scores, marker='o', label='Focal Loss', color='b')\nplt.plot(imbalance_ratios, ce_scores, marker='x', label='Cross-Entropy Loss', color='r')\nplt.xlabel('Imbalance Ratio')\nplt.ylabel('ROC AUC Score')\nplt.title('Effect of Loss Type on Imbalanced Data')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n[LightGBM] [Info] Number of positive: 11, number of negative: 789\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000295 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5100\n[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 20\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.013750 -&gt; initscore=-4.272871\n[LightGBM] [Info] Start training from score -4.272871\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 11, number of negative: 789\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000266 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5100\n[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 20\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.013750 -&gt; initscore=-4.272871\n[LightGBM] [Info] Start training from score -4.272871\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 43, number of negative: 757\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000278 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5100\n[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 20\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.053750 -&gt; initscore=-2.868163\n[LightGBM] [Info] Start training from score -2.868163\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 43, number of negative: 757\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000278 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5100\n[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 20\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.053750 -&gt; initscore=-2.868163\n[LightGBM] [Info] Start training from score -2.868163\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 82, number of negative: 718\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000270 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5100\n[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 20\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102500 -&gt; initscore=-2.169750\n[LightGBM] [Info] Start training from score -2.169750\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 82, number of negative: 718\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000299 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5100\n[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 20\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102500 -&gt; initscore=-2.169750\n[LightGBM] [Info] Start training from score -2.169750\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 161, number of negative: 639\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000311 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5100\n[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 20\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201250 -&gt; initscore=-1.378500\n[LightGBM] [Info] Start training from score -1.378500\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 161, number of negative: 639\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000302 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5100\n[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 20\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201250 -&gt; initscore=-1.378500\n[LightGBM] [Info] Start training from score -1.378500\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 239, number of negative: 561\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000269 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5100\n[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 20\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298750 -&gt; initscore=-0.853257\n[LightGBM] [Info] Start training from score -0.853257\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 239, number of negative: 561\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000259 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5100\n[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 20\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298750 -&gt; initscore=-0.853257\n[LightGBM] [Info] Start training from score -0.853257\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 318, number of negative: 482\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000269 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5100\n[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 20\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.397500 -&gt; initscore=-0.415893\n[LightGBM] [Info] Start training from score -0.415893\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 318, number of negative: 482\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5100\n[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 20\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.397500 -&gt; initscore=-0.415893\n[LightGBM] [Info] Start training from score -0.415893\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 396, number of negative: 404\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5100\n[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 20\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495000 -&gt; initscore=-0.020001\n[LightGBM] [Info] Start training from score -0.020001\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 396, number of negative: 404\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000258 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5100\n[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 20\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495000 -&gt; initscore=-0.020001\n[LightGBM] [Info] Start training from score -0.020001\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n\n\n==&gt; Sử dụng \\(\\alpha\\) và \\(\\gamma\\) chưa tunning trên nhiều kịch bản imbalance khác nhau, gini không có sự khác biệt"
  },
  {
    "objectID": "machine-learning/CohortFitDistribution.html",
    "href": "machine-learning/CohortFitDistribution.html",
    "title": "Fit Distribution",
    "section": "",
    "text": "Phân phối bao gồm: Cauchy, Gamma, Exponential, Log-Logistic, Log-Normal Hàm mât đô xác suất (PDF) của phân phối Cauchy:\n\\[\nf\\left(x ; x_{0} ; \\gamma\\right)=\\frac{1}{\\pi \\gamma\\left[1+\\left(\\frac{x-x_{0}}{\\gamma}\\right)^{2}\\right]}=\\frac{1}{\\pi \\gamma}\\left[\\frac{\\gamma^{2}}{\\left(x-x_{0}\\right)^{2}+\\gamma^{2}}\\right]\n\\]\nTrong đó:\n\n$ x_{0}$ : là thông số vị trí, chỉ định vị trí đỉnh của phân phối\n$ $ : là thông số tỷ lệ chỉ định nửa chiều rộng ở nửa tối đa (HWHM), \\(2 \\gamma\\) là toàn bộ chiều rộng ở mức tối đa một nửa (FWHM). \\(\\gamma\\) là một nửa phạm vi liên phần và đôi khi được gọi là lỗi có thể xảy ra\n\nHàm mât đô xác suất (PDF) của phân phối Gamma:\n\\[\nf(x ; k ; \\theta)=\\frac{x^{k-1} e^{-\\frac{x}{\\theta}}}{\\theta^{k} \\Gamma(k)}, \\text { for } x&gt;0 \\text { and } k, \\theta&gt;0\n\\]\n\n\\(k\\) : là tham số hình dạng\n\\(\\theta\\) : là tham số tỷ lệ\n\\(x\\) : là biến ngẫu nhiên\n\\(\\Gamma(k)\\) : là hàm gamma được đánh giá tại \\(\\mathrm{k}\\)\n\nHàm mật đô xác suất (PDF) của phân phối Exponential:\n\\[\nf(x ; \\lambda)=\\left\\{\\begin{array}{rr}\n0, & x&lt;0 \\\\\n\\lambda e^{-\\lambda x}, & x \\geq 0\n\\end{array}\\right.\n\\]\n\n\\(\\lambda\\) : là tham số của phân phối, thường được gọi là tham số tỷ lệ.\n$ x$ : là biến ngẫu nhiên\n\nHàm mật độ xác suất (PDF) của phân phối Log-Logistic:\n\\[\nf(x ; \\alpha ; \\beta)=\\frac{\\left(\\frac{\\beta}{\\alpha}\\right)\\left(\\frac{x}{\\alpha}\\right)^{\\beta-1}}{\\left(1+\\left(\\frac{x}{\\alpha}\\right)^{\\beta}\\right)^{2}}, \\text { where } x&gt;0, \\alpha&gt;0, \\beta&gt;0\n\\]\n\n\\(\\alpha\\) : là tham số tỷ lệ và là giá trị trung bình của phân phối\n\\(\\beta\\) : là tham số hình dạng\n\nHàm mât độ xác suất (PDF) của phân phối Lognormal \\(\\left(\\mu, \\sigma^{2}\\right)\\) :\n\\[\nf_{x}(x)=\\frac{d}{d x} \\operatorname{Pr}(X \\leq x)=\\frac{1}{x \\sigma \\sqrt{2 \\pi}} e^{\\left(-\\frac{(\\ln x-\\mu)^{2}}{2 \\sigma^{2}}\\right)}, \\text { where } x&gt;0, \\sigma&gt;0\n\\]\n\n\\(x\\) là biến ngẫu nhiên\nMột biến ngẫu nhiên \\(X\\) tuân theo phân phối Log-normal \\(\\left(X \\sim \\operatorname{Lognormal}\\left(\\mu_{x}, \\sigma_{x}^{2}\\right)\\right)\\) nếu \\(\\ln (X)\\) tuân theo phân phối chuẩn với giá trị trung bình là \\(\\mu\\) và phương sai \\(\\sigma^{2}\\)\n\nĐể lựa chọn phân phối phù hợp cho từng phân nhóm, Nhóm mô hình lựa chọn mô hình có SSE (Sum of square error - tổng của sai số bình phương) nhỏ nhất với SSE được tính theo công thức sau:\n\\[\n\\left.S S E=\\sum \\text { (Giá trị thực tế - Giá trị được tính ra từ mô hình phân phối }\\right)^{2}\n\\]\nCuối cùng, từ mô hình phân phối vừa được lựa chọn (là mô hình có SSE nhỏ nhất)."
  },
  {
    "objectID": "machine-learning/CohortFitDistribution.html#dạng-hàm-phân-phối",
    "href": "machine-learning/CohortFitDistribution.html#dạng-hàm-phân-phối",
    "title": "Fit Distribution",
    "section": "",
    "text": "Phân phối bao gồm: Cauchy, Gamma, Exponential, Log-Logistic, Log-Normal Hàm mât đô xác suất (PDF) của phân phối Cauchy:\n\\[\nf\\left(x ; x_{0} ; \\gamma\\right)=\\frac{1}{\\pi \\gamma\\left[1+\\left(\\frac{x-x_{0}}{\\gamma}\\right)^{2}\\right]}=\\frac{1}{\\pi \\gamma}\\left[\\frac{\\gamma^{2}}{\\left(x-x_{0}\\right)^{2}+\\gamma^{2}}\\right]\n\\]\nTrong đó:\n\n$ x_{0}$ : là thông số vị trí, chỉ định vị trí đỉnh của phân phối\n$ $ : là thông số tỷ lệ chỉ định nửa chiều rộng ở nửa tối đa (HWHM), \\(2 \\gamma\\) là toàn bộ chiều rộng ở mức tối đa một nửa (FWHM). \\(\\gamma\\) là một nửa phạm vi liên phần và đôi khi được gọi là lỗi có thể xảy ra\n\nHàm mât đô xác suất (PDF) của phân phối Gamma:\n\\[\nf(x ; k ; \\theta)=\\frac{x^{k-1} e^{-\\frac{x}{\\theta}}}{\\theta^{k} \\Gamma(k)}, \\text { for } x&gt;0 \\text { and } k, \\theta&gt;0\n\\]\n\n\\(k\\) : là tham số hình dạng\n\\(\\theta\\) : là tham số tỷ lệ\n\\(x\\) : là biến ngẫu nhiên\n\\(\\Gamma(k)\\) : là hàm gamma được đánh giá tại \\(\\mathrm{k}\\)\n\nHàm mật đô xác suất (PDF) của phân phối Exponential:\n\\[\nf(x ; \\lambda)=\\left\\{\\begin{array}{rr}\n0, & x&lt;0 \\\\\n\\lambda e^{-\\lambda x}, & x \\geq 0\n\\end{array}\\right.\n\\]\n\n\\(\\lambda\\) : là tham số của phân phối, thường được gọi là tham số tỷ lệ.\n$ x$ : là biến ngẫu nhiên\n\nHàm mật độ xác suất (PDF) của phân phối Log-Logistic:\n\\[\nf(x ; \\alpha ; \\beta)=\\frac{\\left(\\frac{\\beta}{\\alpha}\\right)\\left(\\frac{x}{\\alpha}\\right)^{\\beta-1}}{\\left(1+\\left(\\frac{x}{\\alpha}\\right)^{\\beta}\\right)^{2}}, \\text { where } x&gt;0, \\alpha&gt;0, \\beta&gt;0\n\\]\n\n\\(\\alpha\\) : là tham số tỷ lệ và là giá trị trung bình của phân phối\n\\(\\beta\\) : là tham số hình dạng\n\nHàm mât độ xác suất (PDF) của phân phối Lognormal \\(\\left(\\mu, \\sigma^{2}\\right)\\) :\n\\[\nf_{x}(x)=\\frac{d}{d x} \\operatorname{Pr}(X \\leq x)=\\frac{1}{x \\sigma \\sqrt{2 \\pi}} e^{\\left(-\\frac{(\\ln x-\\mu)^{2}}{2 \\sigma^{2}}\\right)}, \\text { where } x&gt;0, \\sigma&gt;0\n\\]\n\n\\(x\\) là biến ngẫu nhiên\nMột biến ngẫu nhiên \\(X\\) tuân theo phân phối Log-normal \\(\\left(X \\sim \\operatorname{Lognormal}\\left(\\mu_{x}, \\sigma_{x}^{2}\\right)\\right)\\) nếu \\(\\ln (X)\\) tuân theo phân phối chuẩn với giá trị trung bình là \\(\\mu\\) và phương sai \\(\\sigma^{2}\\)\n\nĐể lựa chọn phân phối phù hợp cho từng phân nhóm, Nhóm mô hình lựa chọn mô hình có SSE (Sum of square error - tổng của sai số bình phương) nhỏ nhất với SSE được tính theo công thức sau:\n\\[\n\\left.S S E=\\sum \\text { (Giá trị thực tế - Giá trị được tính ra từ mô hình phân phối }\\right)^{2}\n\\]\nCuối cùng, từ mô hình phân phối vừa được lựa chọn (là mô hình có SSE nhỏ nhất)."
  },
  {
    "objectID": "machine-learning/CohortFitDistribution.html#python-example",
    "href": "machine-learning/CohortFitDistribution.html#python-example",
    "title": "Fit Distribution",
    "section": "Python Example",
    "text": "Python Example\n\nimport numpy as np\nimport pandas as pd\nimport scipy  \nfrom scipy import stats \nimport scipy.optimize as optimize\n\n\n1. Các hàm liên quan\n\n1.1 Hàm phân phối gamma\n\nclass opt_gamma:\n\n    def __init__(self, actual_pd):\n        self.actual_pd = actual_pd\n        self.x_input = range(1, len(actual_pd) + 1)\n\n    def func(self, x, scale, a, b):        \n        predict = stats.gamma.pdf(x, a = a, scale = b) * scale\n        return predict\n\n    def sse(self, params, xobs, yobs):\n        ynew = self.func(xobs, *params)\n        mse = np.sum((ynew - yobs) ** 2)        \n        return mse\n    \n    def solver(self):\n        p0 = [1,1,1]\n        bounds = [(0.0001, 2), (0.0001, 10), (0.0001, 10)]\n        res = scipy.optimize.minimize(self.sse, p0, args=(self.x_input, self.actual_pd), bounds= bounds)       \n        # res = scipy.optimize.minimize(self.sse, p0, args=(self.x_input, self.actual_pd), method='Nelder-Mead')        \n        return res\n    \n    def predict(self, t=30):\n        res = self.solver()\n        ypred = self.func(range(1, t+1), *res.x)        \n        return ypred        \n\n\n\n1.2 Hàm Phân phối mũ Exponential\n\nclass opt_exponential:\n\n    def __init__(self, actual_pd):\n        self.actual_pd = actual_pd\n        self.x_input = range(1, len(actual_pd) + 1)\n\n    def func(self, x, scale, a):        \n        # change function here        \n        pred = stats.expon.pdf(x, scale = 1/a) * scale\n        return pred\n\n    def sse(self, params, xobs, yobs):\n        ynew = self.func(xobs, *params)\n        mse = np.sum((ynew - yobs) ** 2)        \n        return mse\n    \n    def solver(self):\n        # change initial guess here\n        p0 = [1,2]\n        bounds = [(0.0001, 2), (0.0001, 0.5)]           \n        res = scipy.optimize.minimize(self.sse, p0, args=(self.x_input, self.actual_pd), bounds = bounds)             \n        return res\n    \n    def predict(self, t=30):\n        res = self.solver()\n        ypred = self.func(range(1, t+1), *res.x)        \n        return ypred       \n\n\n\n1.3 Hàm phân phối Cauchy\n\nclass opt_cauchy:\n\n    def __init__(self, actual_pd):\n        self.actual_pd = actual_pd\n        self.x_input = range(1, len(actual_pd) + 1)\n\n    def func(self, x, scale, a, b):        \n        # change function here        \n        predict = stats.cauchy.pdf(x, loc = b, scale = a) * scale\n        return predict\n\n    def sse(self, params, xobs, yobs):\n        ynew = self.func(xobs, *params)\n        mse = np.sum((ynew - yobs) ** 2)        \n        return mse\n    \n    def solver(self):\n        # change initial guess here\n        p0 = [1,1,1]\n        bounds = [(0.0001, 2), (0.0001, 15), (-30, 30)]\n        res = scipy.optimize.minimize(self.sse, p0, args=(self.x_input, self.actual_pd), bounds = bounds)        \n        return res\n    \n    def predict(self, t=30):\n        res = self.solver()\n        ypred = self.func(range(1, t+1), *res.x)        \n        return ypred    \n\n\n\n1.4 Hàm phân phối log logistic\n\nclass opt_log_logistic:\n\n    def __init__(self, actual_pd):\n        self.actual_pd = actual_pd\n        self.x_input = range(1, len(actual_pd) + 1)\n\n    def func(self, x, scale, a, b):        \n        # change function here\n        predict = scale*(a/b)*(x/b)**(a-1)/(1+(x/b)**a)**2\n        return predict\n\n    def sse(self, params, xobs, yobs):\n        ynew = self.func(xobs, *params)\n        mse = np.sum((ynew - yobs) ** 2)        \n        return mse\n    \n    def solver(self):\n        # change initial guess here\n        p0 = [2,3,1]\n        bounds = [(0.0001, 2), (0.0001, 10), (0.0001, 10)]\n        res = scipy.optimize.minimize(self.sse, p0, args=(self.x_input, self.actual_pd), bounds=bounds)        \n        return res\n    \n    def predict(self, t=30):\n        res = self.solver()\n        ypred = self.func(range(1, t+1), *res.x)        \n        return ypred    \n\n\n\n1.5 Hàm phân phối log normal\n\nclass opt_log_normal:\n\n    def __init__(self, actual_pd):\n        self.actual_pd = actual_pd\n        self.x_input = range(1, len(actual_pd) + 1)\n\n    def func(self, x, scale, a, b):        \n        # change function here\n        predict = (np.exp(-(np.log(x) - a)**2 / (2 * b**2)) / (x * b * np.sqrt(2 * np.pi)))*scale\n        return predict\n\n    def sse(self, params, xobs, yobs):\n        ynew = self.func(xobs, *params)\n        mse = np.sum((ynew - yobs) ** 2)        \n        return mse\n    \n    def solver(self):\n        # change initial guess here\n        p0 = [1,1,1]\n        bounds = [(0.0001, 2), (0.0001, 0.5), (0.0001, 0.5)]\n        res = scipy.optimize.minimize(self.sse, p0, args=(self.x_input, self.actual_pd), bounds=bounds)        \n        return res\n    \n    def predict(self, t=30):\n        res = self.solver()\n        ypred = self.func(range(1, t+1), *res.x)        \n        return ypred"
  },
  {
    "objectID": "machine-learning/CohortFitDistribution.html#fit-models",
    "href": "machine-learning/CohortFitDistribution.html#fit-models",
    "title": "Fit Distribution",
    "section": "2. Fit models",
    "text": "2. Fit models\n\n2.1 Đặt giá trị initial\n\nGamma = 1,1,1\nCauchy = 1,1,1\nExpo = 1,2\nLog Logistic = 2,3,1\nLog Normal = 1,1,1\n\n\n\n2.2 Đọc dữ liệu\n\ndata = pd.read_excel('results/Cohort Analysis.xlsb', engine='pyxlsb', sheet_name='1.2 Visualize', usecols = 'O:Z')\ndata.tail()"
  },
  {
    "objectID": "machine-learning/CohortFitDistribution.html#fit-models-1",
    "href": "machine-learning/CohortFitDistribution.html#fit-models-1",
    "title": "Fit Distribution",
    "section": "2.3 Fit models",
    "text": "2.3 Fit models\n\ndef fn_export_by_segment(segment, period):\n    # segment = segment.upper()\n    actual_pd = data[data.Segment_Group.isin([segment])]\n    actual_pd = actual_pd.iloc[0, 2:]\n    actual_pd = actual_pd.values\n    \n    res_gamma = opt_gamma(actual_pd)\n    res_exponential = opt_exponential(actual_pd)\n    res_cauchy = opt_cauchy(actual_pd)\n    res_log_logistic = opt_log_logistic(actual_pd)\n    res_log_normal = opt_log_normal(actual_pd)\n    \n    params = pd.DataFrame({\n        'Segment': segment,\n        'Distribution': ['Gamma', 'Exponential', 'Cauchy', 'Log-Logistic', 'Log-Normal'],\n        'SSE': [res_gamma.solver().fun, res_exponential.solver().fun, res_cauchy.solver().fun, res_log_logistic.solver().fun, res_log_normal.solver().fun],\n        'params': [res_gamma.solver().x, res_exponential.solver().x, res_cauchy.solver().x, res_log_logistic.solver().x, res_log_normal.solver().x]\n    })    \n   \n    params[['scale', 'a', 'b']] = pd.DataFrame(params.params.to_list())    \n    del params['params']\n    \n    dict_predict = {\n            'Segment': segment,\n            'Period': range(1, period+1),\n            'Gamma': res_gamma.predict(period),\n            'Exponential': res_exponential.predict(period),\n            'Cauchy': res_cauchy.predict(period),\n            'Log-Logistic': res_log_logistic.predict(period),\n            'Log-Normal': res_log_normal.predict(period)\n        }\n    \n    best_distribution = params.sort_values('SSE').head(1)\n    best_distribution['Tag best distribution'] = 'Best distribution'    \n\n    print('Best distribution of ' + segment + ' is '+ best_distribution['Distribution'].item())\n\n    return params, best_distribution, pd.DataFrame(dict_predict)\n\n\npred_best_fit = []\nparams_frame = []\npred_all_curve = []\nfor seg in data.Segment_Group:\n    params, df_best_fit, df_all = fn_export_by_segment(seg, 30)\n    pred_best_fit.append(df_best_fit)\n    params_frame.append(params)\n    pred_all_curve.append(df_all)\n\npred_best_fit = pd.concat(pred_best_fit, axis=0)\nparams_frame = pd.concat(params_frame, axis=0)\npred_all_curve = pd.concat(pred_all_curve, axis=0)\n\n\npivot_pred_all_curve = pd.melt(pred_all_curve, \n        id_vars=['Segment', 'Period'], \n        value_vars=['Gamma', 'Exponential', 'Cauchy', 'Log-Logistic', 'Log-Normal'],\n        var_name = 'Distribution').pivot(\n                index = ['Segment', 'Distribution'], columns='Period'\n        )\npivot_pred_all_curve.reset_index(inplace=True, drop=False)\npivot_pred_all_curve.columns = ['Segment', 'Distribution', *range(1,31)]\npivot_pred_all_curve = params_frame.merge(pivot_pred_all_curve, how='inner', on=['Segment', 'Distribution']).merge(\n        pred_best_fit[['Segment', 'Distribution', 'Tag best distribution']], how='left', on=['Segment', 'Distribution']\n)"
  }
]